<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>常用图表</title>
      <link href="/2019/11/07/chang-yong-tu-biao/"/>
      <url>/2019/11/07/chang-yong-tu-biao/</url>
      
        <content type="html"><![CDATA[<p>看一下代表两种思维的场景。</p><ol><li><p>我们12月的销售额度下降，我想是因为年终的影响，我问了几个销售员，他们都说年终生意不太好做，各家都收紧了财务预算，谈下的几家费用也比以前有缩水。我对他们进行了电话拜访，厂家都说经济不景气，希望我们价格方面再放宽点。</p></li><li><p>我们12月的销售额度下降，低于去年同期和今年平均值，可以排除掉大环境的因素。其中A地区下降幅度最大，间接影响了整体销售额。通过调查发现，A地区的市场因为竞争对手涌入，进行了低价销售策略。除此之外，B地区的经济发展低于预期发展，企业缩减投入。</p></li></ol><p>第一个==分析思维是依赖经验和直觉的线性思维==，第二个分析思维则==注重逻辑推导，属于结构化的思维==。两种思维往往会导致不同的结果。</p><p>如果没有刻意训练，很多人的思维方式都倾向第一种，以“我觉得我认为”展开。经验主义虽然重要，但不正确的使用也会约束和限制我们。</p><h2 id="运营中典型的金字塔思维（金字塔思维则是总-分-再分）："><a href="#运营中典型的金字塔思维（金字塔思维则是总-分-再分）：" class="headerlink" title="运营中典型的金字塔思维（金字塔思维则是总-分-再分）："></a>运营中典型的金字塔思维（金字塔思维则是总-分-再分）：</h2><ol><li><p>我们活跃用户数在下降（中心论点），主要原因是竞争加剧（分论点），其次原因是新用户减少（分论点），老用户流失加快（分论点）。其中竞争加剧是因为竞争对手ABC出现（论据），新用户减少是ASO排名下降（论据）和渠道投入疲软（论据）造成，老用户流失是因为产品欠佳（论据）。我建议……</p><p> 这是合格运营的结构化思考。如果你把它换成一名初级运营的思考方式：</p></li><li><p>Boss，我发现我们最近的ASO排名下降了不少，渠道投入也减少，导致用户数少了不少。对了，最近产品表现也欠佳，有几家模仿我们的竞争对手出现，对我们造成了影响。这个影响应该会让我们减少一些用户。我建议……</p><p> 这种表达方式就是有什么说什么，想到哪就是哪，接听者的思维方式被无序地牵着鼻子走</p></li></ol><p>绝大多数的商业项目、数据分析、业务讨论，都可以抽象成公式：</p><pre><code>利润 = 销售额 – 成本；销售额 = 购买人数 * 转化率 * 客单价；购买人数 = 地区A购买人数+地区B购买人数+……地区A购买人数 = 地区A新用户 + 地区A老用户；</code></pre><p>举一个具体问题：企业利润下降了，是什么原因？我们就能用公式分解出分论点。</p><p>==是销售额下降了？还是成本上升？==</p><p>==如果是销售额下降，那么是购买人数少了？是客单价下降了？还是购买转化率降低？==</p><p>以此类推，则能形成结构化的分析思路</p><h2 id="不要为分析而分析（使用假设先行）"><a href="#不要为分析而分析（使用假设先行）" class="headerlink" title="不要为分析而分析（使用假设先行）"></a>不要为分析而分析（使用假设先行）</h2><p>什么是假设先行？就是以假设作为思考的起点。我不需要做全局的思考，而是==先问出一个问题，然后思考解决它==：我这款产品的特点在A功能吗？这款产品对用户们很有吸引力吗？我的活动如何在朋友圈引发传播？怎么让用户在活动中更爽？</p><p>在做出假设后，引导思维去挖掘分论点，然后分析。比如我希望活动传播，我要考虑哪些人会传播，他们是因为利益引诱还是情感触动？传播的过程应该什么样，方便还是复杂？这样的分析思维，比堪堪想一个空中楼阁的完美方案靠谱多了。</p><p>分析思维和数据分析不一样，==数据分析追求数据的精确度，而分析思维不需要，只要能回答问题，是和否足够==了。</p><p>假设会被否定或者拒绝，我认为产品对用户有吸引力，但是最后所有的论据，包括留存率、用户使用时长、功能使用率、用户评价都是否定，那么吸引力也就不成立，此时应该修改假设：产品的某一方面有问题，然后继续画新的问题树。</p><h2 id="关键驱动因素是分析的核心，应该聚焦于这些因素"><a href="#关键驱动因素是分析的核心，应该聚焦于这些因素" class="headerlink" title="关键驱动因素是分析的核心，应该聚焦于这些因素"></a>关键驱动因素是分析的核心，应该聚焦于这些因素</h2><p>企业利润的关键驱动因素是利润和成本，用户吸引力的关键驱动因素是留存率。利润和成本还能再找出其中的细分关键因素，留存率也一样。这才是我们要的。</p><p>一旦找到关键驱动因素，可以基于此展开数据调研、取证、分析和结论，而不是对所有问题树开展</p><h3 id="28法则"><a href="#28法则" class="headerlink" title="28法则"></a>28法则</h3><p>在任何一组东西中，最重要的只占其中一小部分，约20%，其余80%尽管是多数，却是次要的。80%的成绩，归功于20%的努力；市场上80%的产品可能是20%的企业生产的；20%的顾客可能给商家带来80%的利润……</p><p>不论你分析企业的利润、还是用户的活跃，只要抓住关键即可。因为一款内容产品，80%的内容一定由核心用户提供；一款电商产品，80%的GMV一定是少部分买买买用户下单。围绕核心关键因素展开的数据分析，是最有效果的。</p><h2 id="正确分析流程"><a href="#正确分析流程" class="headerlink" title="正确分析流程"></a>正确分析流程</h2><p>提出假设—MECE原则（万能公式）—结构化分析—找出关键驱动因素—数据分析</p><h2 id="具体案例"><a href="#具体案例" class="headerlink" title="具体案例"></a>具体案例</h2><p>假设你是一位商业经理，现在有一家中型商场，我希望你对它的经营状况作出分析，你会从哪几个角度展开，列出你的框架。</p><p>既然是针对经营状况作分析，那么核心希望肯定是提高经营，先行假设就是如何提高经营状况。我们用MECE画出问题树。</p><p>先找到万能公式，上文提到过，绝大多数商业活动，都是利润和成本的平衡。</p><p>经营 = 利润-成本</p><p>我们可以通过提高利润，降低成本作为两个分论点展开。我们再考虑有哪些利润，无非是商场各类产品和服务的售卖。它又能拆解出几个公式。</p><p>利润 = 人流 * 转化率 * 客单价</p><p>不同的产品和服务各有不同，人流是固定的，而转化率因为商场的不同产品和服务会划分成ABC的差异。</p><p>利润 = 人流<em>（A转化率</em>A客单价+B转化率*B客单价……）</p><p>成本则考虑房租、资产折旧、人员工资等。是否需要考虑商场贩卖的产品成本？需要的，但是不应该放在这里，因为要遵循MECE原则的完全独立，利润中的客单价已经包含产品这类成本，所以应该归类到利润下。</p><p>再进行深度的结构划分，比如人流各楼层不同，一楼人气最旺，然后依次衰减，那么结构中能不能体现？还有其他分论点吗？都能想想。之后找出问题树的关键驱动因素，并且思考如何提高。</p><p>这是一道开放的分析思维题，答案并不固定。我也并不要求商业知识和商场管理知识多严谨，考察的是能否通过生活中随处可见的商场，通过自己思维去抽象出一套框架。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图表 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分析思维养成</title>
      <link href="/2019/11/07/fen-xi-si-wei-yang-cheng/"/>
      <url>/2019/11/07/fen-xi-si-wei-yang-cheng/</url>
      
        <content type="html"><![CDATA[<ol><li><p>了解和使用指标是数据分析思维的第一步，不要用我觉得。</p><pre><code>若有一位运营和你说，产品表现不错，因为每天都有很多人评价和称赞，还给你看了几个截图。而另外一位运营说，产品有些问题，推的活动商品卖的不好，你应该相信谁呢？ 其实谁都很难相信，这些众口异词的判断都是因为缺乏数据分析思维造成的。 老王想要描述生意，他应该使用销量，这就是他的指标，互联网想要描述产品，也应该使用活跃率、使用率、转化率等指标。</code></pre></li><li><p>孤立的指标发挥不出数据的价值。和分析思维一样，指标也能结构化，也应该用结构化。<br><img src="https://image.yunyingpai.com/wp/2018/10/ZiL74kNpGqzE1sLDICqu.png" alt="image"></p></li><li><p>指标化<br><img src="https://image.yunyingpai.com/wp/2018/10/8EXXtbr0ObKZxh7QFa2B.png" alt="image"><br>投资回报率（ROI)</p><p> 指标体系没有放之四海而皆准的模板，不同业务形态有不同的指标体系。移动APP和网站不一样，SaaS和电子商务不一样，低频消费和高频消费不一样。好比一款婚庆相关的APP，不需要考虑复购率指标；互联网金融，必须要风控指标；电子商务，卖家和买家的指标各不一样。</p></li><li><p>好指标应该是核心驱动指标。虽然指标很重要，但是有些指标需要更重要。就像销量和利润，用户数和活跃用户数，后者都比前者重要。</p><pre><code> 只看销量不靠谱（例子如下） 最近物价上涨，老王顺应调高了水果价格，又不敢涨的提高，虽然水果销量没有大变化，但老王发现一个月下来没赚多少，私房钱都不够存。 老王这个月的各类水果销量有2000，但最后还是亏本了，仔细研究后发现，虽然销量高，但是水果库存也高，每个月都有几百单位的水果滞销最后过期亏本。</code></pre><p> 核心驱动指标和公司发展关联，是公司在一个阶段内的重点方向。记住是一个阶段，不同时期的核心驱动指标不一样。不同业务的核心驱动指标也不一样。</p></li><li><p>==互联网公司常见的核心指标是用户数和活跃率，用户数代表市场的体量和占有，活跃率代表产品的健康度，但这是发展阶段的核心指标==。在产品1.0期间，我们应把注意力放到打磨产品上，在大推广前提高产品质量，这时留存率是一个核心指标。而在有一定用户基数的产品后期，商业化比活跃重要，我们会关注钱相关的指标，比如广告点击率、利润率等。</p></li><li><p>核心驱动指标一定能给公司和个人带来最大优势和利益，记得二八法则么？20%的指标一定能带来80%的效果，这20%的指标就是核心。</p><p> 另外一方面，==好的指标==还有一个特性，它应该==是比率或者比例==</p><p> 拿活跃用户数说明就懂了，我们活跃用户有10万，这能说明什么呢？这说明不了什么。如果产品本身有千万级别的注册用户，那么10万用户说明非常不健康，产品在衰退期。如果产品只拥有四五十万用户，那么说明产品的粘性很高</p></li><li><p>坏指标</p><p> 其一是==虚荣指标==，它没有任何的实际意义。</p><p> 产品在应用商店有几十万的曝光量，有意义吗？没有，我需要的是实际下载。下载了意义大吗？也不大，我希望用户注册成功。==曝光量和下载量都是虚荣指标==，只是虚荣程度不一样。</p><p> ==新媒体都追求微信公众号阅读数，如果靠阅读数做广告，那么阅读数有意义，如果靠图文卖商品，那么更应该关注转化率和商品销量，毕竟一个夸张的标题就能带来很高的阅读量，此时的阅读量是虚荣指标==。可惜很多老板还是孜孜不倦的追求10W+，哪怕刷量。</p><p> 第二个坏指标是==后验性指标==，它往往只能反应已经发生的事情。</p><p> 比如我有一个流失用户的定义：三个月没有打开APP就算做流失。那么运营每天统计的流失用户数，都是很久没有打开过的，以时效性看，已经发生很久了，也很难通过措施挽回。我知道曾经因为某个不好的运营手段伤害了用户，可是还有用吗？</p><p> ==活动运营的ROI（投资回报率）也是后验性指标==，一个活动付出成本后才能知道其收益。可是成本已经支出，活动的好与坏也注定了。==活动周期长，还能有调整余地==。活动短期的话，这指标只能用作复盘，但不能驱动业务。</p><p> 第三个坏指标是==复杂性指标==，它将数据分析陷于一堆指标造成的陷阱中。</p><p> 指标能细分和拆解，比如==活跃率可以细分成日活跃率、周活跃率、月活跃率、老用户活跃率==等。数据分析应该根据具体的情况选择指标，如果是==天气类工具，可以选择日活跃率，如果是社交APP，可以选择周活跃率，更低频的产品则是月活跃率==。</p><p> 每个产品都有适合它的几个指标，不要一股脑的装一堆指标上去，当你准备了二三十个指标用于分析，会发现无从下手。</p></li><li><p>如何正确的选择指标？</p><p> 假设你是内容运营，需要对现有的业务做一个分析，提高内容相关数据，你会怎么做呢？</p><p> 我们把金字塔思维转换一下，就成了数据分析方法了。</p><p> 从内容运营的流程开始，它是：==内容收集—内容编辑发布—用户浏览—用户点击—用户阅读—用户评论或转发—继续下一篇浏览==。</p><p> 这是一个标准的流程，每个流程都有指标可以建立。内容收集可以建立热点指数，看哪一篇内容比较火。用户浏览用户点击则是标准的PV和UV统计，用户阅读是阅读时长。<br> <img src="https://image.yunyingpai.com/wp/2018/10/egyYe696i29BRR9YB9Vh.png" alt="image"></p></li><li><p>有了指标之后，就可以运用下面三个方法进行数据分析了</p><p> 第一类是利用==维度分析数据，第二类是使用统计学知识如数据分布假设检验，最后一类是使用机器学习==。我们先了解一下维度分析法。</p><p> 维度是描述对象的参数，在具体分析中，我们可以把它认为是分析事物的角度。销量是一种角度、活跃率是一种角度，时间也是一种角度，所以它们都能算维度</p><p> ==谈到维度法==，想要强调的是分析的核心思维之一：==对比==，不同维度的对比，这大概是对新人快速提高的最佳捷径之一。比如过去和现在的时间趋势对比，比如不同地区维度的对比，比如产品类型的区别对比，比如不同用户的群体对比。单一的数据没有分析意义，==只有多个数据组合才能发挥出数据的最大价值==。</p><p>== 我们通过业务建立和筛选出指标，将指标作为维度，利用维度进行分析。==</p></li></ol><h3 id="维度和指标的区别"><a href="#维度和指标的区别" class="headerlink" title="维度和指标的区别"></a>维度和指标的区别</h3><p>维度是说明和观察事物的角度，指标是衡量数据的标准。维度是一个更大的范围，不只是数据，比如时间维度和城市维度，我们就无法用指标表示，而==指标（留存率、跳出率、浏览时间等）却可以成为维度。通俗理解：维度&gt;指标==。</p><h3 id="什么是用户画像？"><a href="#什么是用户画像？" class="headerlink" title="什么是用户画像？"></a>什么是用户画像？</h3><p>通常理解就是给用户打的各种标签就是用户画像</p><p>用户画像的应用：</p><pre><code>1. 精准营销：这是运营最熟悉的玩法，从粗放式到精细化，将用户群体切割成更细的粒度，辅以短信、推送、邮件、活动等手段，驱以关怀、挽回、激励等策略。2. 数据应用：用户画像是很多数据产品的基础，诸如耳熟能详的推荐系统广告系统。操作过各大广告投放系统的同学想必都清楚，广告投放基于一系列人口统计相关的标签，性别、年龄、学历、兴趣偏好、手机等等。3. 用户分析：虽然和Persona不一样，用户画像也是了解用户的必要补充。产品早期，PM们通过用户调研和访谈的形式了解用户。在产品用户量扩大后，调研的效用降低，这时候会辅以用户画像配合研究。新增的用户有什么特征，核心用户的属性是否变化等等。4. 数据分析：这个就不用多提了，用户画像可以理解为业务层面的数据仓库，各类标签是多维分析的天然要素。数据查询平台会和这些数据打通。</code></pre><p>现在运营按用户生命周期设立了几个标签，比如新用户、活跃用户、流失用户，这些标签当然够细分。但它真的是一个好标签么？不是。</p><p>聪明的运营会设立一个新的标签，最近一次活跃距今天数，用户有六个月没有活跃，那么天数就是180天。这个比单纯的流失用户标签好，能凭此划分不同的距今天数，设立30天，90天，180天的时间节点。</p><p>距今天数也不是最好的。用户有差异，同样两个用户A和B，哪怕不活跃天数相同，我也不能认为它们的流失可能性相等。该问题在低频场景更凸显，旅游APP，半年没有活跃也是正常的，此时距今天数力有未逮。</p><p>回过头看流失用户，我们定义它，不是为了设立一个高大上的系统。任何企业，肯定一开始就希望流失用户越少越好，其次才是如何挽回。这种业务前提下，预防性的减少流失用户比已经流失的标签更重要。</p><p>所以，最好的标签的标签是用户流失概率：</p><p>流失概率&gt;距今消费天数&gt;流失标签</p><p>猜用户是男是女，哪里人，工资多少，有没有谈恋爱，喜欢什么，准备剁手购物吗？探讨这些是没有意义的。是男是女如何影响消费决策，工资多少影响消费能力，有没有谈恋爱会否带来新的营销场景，剁手购物怎么精准推荐，这些才是用户画像背后的逻辑。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 思维养成 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据清洗常见方法</title>
      <link href="/2019/11/07/shu-ju-qing-xi/"/>
      <url>/2019/11/07/shu-ju-qing-xi/</url>
      
        <content type="html"><![CDATA[<h1 id="减少IO量"><a href="#减少IO量" class="headerlink" title="减少IO量"></a>减少IO量</h1><ol><li><p>建立分区表</p></li><li><p>只查找有效列</p></li><li><p>where过滤不要的数据</p></li><li><p>limit适当使用</p></li><li><p>合并不同sql，读一次原表做多次计算</p></li><li><p>字查询合并</p><h1 id="计算优化"><a href="#计算优化" class="headerlink" title="计算优化"></a>计算优化</h1></li><li><p>mapjoin优化</p><p>一、应用场景</p><ol><li>大小表数据相差大，小表满足限制条件</li><li>不等值条件，or条件等复杂on条件</li></ol><p>二、限制条件</p><ol><li>left join的左表必须是大表</li><li>right join的右表必须是大表</li><li>inner join左右均可为大表</li><li>full join不能使用mapjoin</li><li>mapjoin支持小表为子查询</li><li>使用mapjoin时，需要引用小表子字查询时，需要引用别名</li><li>mapjoin可以使用不等值或者or连接多个条件</li><li>多表join时，最左边的两个表不能同时是mapjoin的表</li></ol><p>三、数据倾斜，导致长尾</p><ol><li>key热点先去重或者过滤（null，空等）</li><li>显性制定mapjoin</li></ol></li><li><p>两表join时如果字段类型不一样，则使用cast显性转换</p></li><li><p>聚合运算时少用distinct，如果groupby 的key有缺省值，可以尝试将sql改写。</p><pre><code> select pid,sum(price) from sales group by pid(假定存在大量缺省无效值为-1) select newpid,sum(price) from (select case when pid=-1 then concat(rand(),'default') else pid end as newpid from sales) group by newpid</code></pre></li><li><p>多表join时join顺序很重要，优先选择join结果输出小的表先关联</p></li><li><p>动态分区（可能会导致小文件过多），推荐建表时采用写入静态分区</p></li><li><p>使用窗口，内置的udf，避免使用order by</p></li><li><p>适当的做一个中间表，对中间表进行计算</p><h1 id="寻找问题"><a href="#寻找问题" class="headerlink" title="寻找问题"></a>寻找问题</h1></li><li><p>常用explain命令，logview的使用</p></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 脏数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>sql 优化</title>
      <link href="/2019/11/07/sql/"/>
      <url>/2019/11/07/sql/</url>
      
        <content type="html"><![CDATA[<h1 id="减少IO量"><a href="#减少IO量" class="headerlink" title="减少IO量"></a>减少IO量</h1><ol><li><p>建立分区表</p></li><li><p>只查找有效列</p></li><li><p>where过滤不要的数据</p></li><li><p>limit适当使用</p></li><li><p>合并不同sql，读一次原表做多次计算</p></li><li><p>字查询合并</p><h1 id="计算优化"><a href="#计算优化" class="headerlink" title="计算优化"></a>计算优化</h1></li><li><p>mapjoin优化</p><p>一、应用场景</p><ol><li>大小表数据相差大，小表满足限制条件</li><li>不等值条件，or条件等复杂on条件</li></ol><p>二、限制条件</p><ol><li>left join的左表必须是大表</li><li>right join的右表必须是大表</li><li>inner join左右均可为大表</li><li>full join不能使用mapjoin</li><li>mapjoin支持小表为子查询</li><li>使用mapjoin时，需要引用小表子字查询时，需要引用别名</li><li>mapjoin可以使用不等值或者or连接多个条件</li><li>多表join时，最左边的两个表不能同时是mapjoin的表</li></ol><p>三、数据倾斜，导致长尾</p><ol><li>key热点先去重或者过滤（null，空等）</li><li>显性制定mapjoin</li></ol></li><li><p>两表join时如果字段类型不一样，则使用cast显性转换</p></li><li><p>聚合运算时少用distinct，如果groupby 的key有缺省值，可以尝试将sql改写。</p><pre><code> select pid,sum(price) from sales group by pid(假定存在大量缺省无效值为-1) select newpid,sum(price) from (select case when pid=-1 then concat(rand(),'default') else pid end as newpid from sales) group by newpid</code></pre></li><li><p>多表join时join顺序很重要，优先选择join结果输出小的表先关联</p></li><li><p>动态分区（可能会导致小文件过多），推荐建表时采用写入静态分区</p></li><li><p>使用窗口，内置的udf，避免使用order by</p></li><li><p>适当的做一个中间表，对中间表进行计算</p><h1 id="寻找问题"><a href="#寻找问题" class="headerlink" title="寻找问题"></a>寻找问题</h1></li><li><p>常用explain命令，logview的使用</p></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> sql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>拉链表</title>
      <link href="/2019/11/07/lalian/"/>
      <url>/2019/11/07/lalian/</url>
      
        <content type="html"><![CDATA[<h1 id="拉链表的使用场景"><a href="#拉链表的使用场景" class="headerlink" title="拉链表的使用场景"></a>拉链表的使用场景</h1><p>在数据仓库的数据模型设计过程中，经常会遇到下面这种表的设计：</p><p>有一些表的数据量很大，比如一张用户表，大约10亿条记录，50个字段，这种表，即使使用ORC压缩，单张表的存储也会超过100G，在HDFS使用双备份或者三备份的话就更大一些。</p><ol><li>表中的部分字段会被update更新操作，如用户联系方式，产品的描述信息，订单的状态等等。</li><li>需要查看某一个时间点或者时间段的历史快照信息，比如，查看某一个订单在历史某一个时间点的状态。</li><li>表中的记录变化的比例和频率不是很大，比如，总共有10亿的用户，每天新增和发生变化的有200万左右，变化的比例占的很小。</li></ol><p>那么对于这种表我该如何设计呢？下面有几种方案可选：</p><ol><li>方案一：每天只留最新的一份，比如我们每天用Sqoop抽取最新的一份全量数据到Hive中。</li><li>方案二：每天保留一份全量的切片数据。</li><li>方案三：使用拉链表。</li></ol><h2 id="各种方案对应的优缺点"><a href="#各种方案对应的优缺点" class="headerlink" title="各种方案对应的优缺点"></a>各种方案对应的优缺点</h2><ol><li><p>这种方案就不用多说了，实现起来很简单，每天drop掉前一天的数据，重新抽一份最新的。</p><p> 优点很明显，节省空间，一些普通的使用也很方便，不用在选择表的时候加一个时间分区什么的。</p><p> 缺点同样明显，没有历史数据，先翻翻旧账只能通过其它方式，比如从流水表里面抽</p></li><li><p>每天一份全量的切片是一种比较稳妥的方案，而且历史数据也在。<br>缺点就是存储空间占用量太大太大了，如果对这边表每天都保留一份全量，那么每次全量中会保存很多不变的信息，对存储是极大的浪费，这点我感触还是很深的……<br>当然我们也可以做一些取舍，比如只保留近一个月的数据？但是，需求是无耻的，数据的生命周期不是我们能完全左右的。</p></li><li><p>首先它在空间上做了一个取舍，虽说不像方案一那样占用量那么小，但是它每日的增量可能只有方案二的千分之一甚至是万分之一。</p></li></ol><p>其实它能满足方案二所能满足的需求，既能获取最新的数据，也能添加筛选条件也获取历史的数据。</p><ol><li><p>在数仓中设计一张表保存每天的变化情况（类似粉丝表，每天可能有部分粉丝发生状态的变化，取关了等等）</p></li><li><p>所以就存在同一个粉丝的多条记录数据，这时有个规则，新增两个字段==dw_start_date==和==dw_end_date==，dw_start_date表示该条记录的生命周期开始时间，dw_end_date表示该条记录的生命周期结束时间</p></li><li><p>其中==同一个人的最新一条记录==的dw_end_date用==无穷大==表示</p></li><li><p>最终形成的表就叫拉链表，假设这个表叫his_data</p></li><li><p>查询最新的记录数据</p><pre><code> SELECT * FROM his_dataWHERE dw_end_date='9999-12-31';</code></pre></li><li><p>查询某一天的历史快照</p><pre><code> SELECT * FROM his_data WHERE dw_start_date &lt;= '2018-04-01' AND dw_end_date &gt;= '2018-04-01'</code></pre></li></ol><h2 id="拉链表的具体实现"><a href="#拉链表的具体实现" class="headerlink" title="拉链表的具体实现"></a>拉链表的具体实现</h2><p>准备三张表</p><p>原系统订单表orders、数据仓库ODS层增量数据表orders_inc、数据仓库DW层拉链表orders_his</p><pre><code>    CREATE TABLE orders (    orderid INT,    createtime STRING,    modifiedtime STRING,    status STRING    )CREATE TABLE orders_inc (    orderid INT,    createtime STRING,    modifiedtime STRING,    status STRING)PARTITIONED BY (day STRING)CREATE TABLE orders_his (    orderid INT,    createtime STRING,    modifiedtime STRING,    status STRING,    dw_start_date STRING,    dw_end_date STRING)</code></pre><p>其中，增量表可以有如下几个方式获取：</p><ol><li>监控MySQL的数据变化，例如使用Canal、或者ChangeDataCapture或者看update_time，获取最后一条更新的数据</li><li>每天获取一份切片数据，然后对比两天的切片数据获得增量</li><li>源数据库的流水表，例如XXX_log等</li></ol><p>拉链表操作步骤：</p><ol><li><p>全量初始化<br>假设数据仓库从4月1号起启用，那么首先需要在4月1号这一天做全量初始化，需要将4月1号以前(含4.1)的所有数据都抽取并刷新到数据仓库中</p><pre><code> INSERT overwrite TABLE orders_inc PARTITION (day = '2018-04-01') SELECT orderid, createtime, modifiedtime, status FROM orders WHERE createtime &lt;= '2018-04-01'; 然后从ODS层抽取到DW层： INSERT overwrite TABLE orders_his SELECT orderid,c reatetime, modifiedtime, status,     createtime AS dw_start_date,     '9999-12-31' AS dw_end_date FROM orders_inc WHERE day = '2018-04-01';</code></pre></li><li><p>增量抽取</p><p> 从源系统订单表中，将前一天的增量数据抽取到ODS层的增量数据表。这里的增量数据使用订单表中的创建时间和修改时间来确定。</p><p> note：订单表中数据同一天有多次状态更新，取每天的最后一个状态为当天的最终状态</p><pre><code> -- ${day} = '2018-04-02' INSERT overwrite TABLE orders_inc PARTITION (day = '${day}') SELECT orderid, createtime, modifiedtime, status FROM orders WHERE createtime = '${day}' OR modifiedtime = '${day}';</code></pre></li><li><p>放到拉链表中</p><p> 先将增量数据放到临时表中，然后插入DW拉链表</p><pre><code> DROP TABLE IF EXISTS orders_his_tmp;   CREATE TABLE orders_his_tmp AS   SELECT orderid,       createtime,       modifiedtime,       status,       dw_start_date,       dw_end_date   FROM (      -- updated order(将原来拉链表的最后一条记录更新)      SELECT a.orderid,           a.createtime,           a.modifiedtime,           a.status,           a.dw_start_date,           CASE WHEN b.orderid IS NOT NULL AND a.dw_end_date = '9999-12-31' THEN '2018-04-01'               ELSE a.dw_end_date          END AS dw_end_date       FROM orders_his a       LEFT JOIN (SELECT * FROM orders_inc WHERE day = '2018-04-02') b       ON (a.orderid = b.orderid)       UNION ALL       -- new order（找到所有今天新增的记录）     SELECT orderid,           createtime,           modifiedtime,           status,           modifiedtime AS dw_start_date,           '9999-12-31' AS dw_end_date       FROM orders_inc       WHERE day = '2018-04-02'   ) x   ORDER BY orderid,dw_start_date;   INSERT overwrite TABLE dw_orders_his   SELECT * FROM orders_his_tmp;</code></pre></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 表设计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据常见问答</title>
      <link href="/2019/11/07/bigdata/"/>
      <url>/2019/11/07/bigdata/</url>
      
        <content type="html"><![CDATA[<ol><li><p>Yarn 是主流的资源调度系统(Yarn是“Yet Another Resource Negotiator”的缩写，字面意思就是“==另一种资源调度器==”)</p></li><li><p>Yarn主要包括两个重要的部分，一个是资源管理器(resource manager)，一个是节点管理器（node manager）。其中资源管理器进程负责集群上所有资源的调度管理，常部署在==单独的服务器==上，节点管理器进程负责具体服务器资源和任务管理。在==集群的每一台计算服务器上都会启动==，基本上跟==hdfs的datanode一起启动==。</p></li><li><p>shuffle:分布式计算需要将不同服务器的相关数据合并到一起进行下一步计算</p></li><li><p>==MapReduce的主服务器就是JobTracker，从服务器就是TaskTracker==。还记得我们讲HDFS也是主从架构吗，==HDFS的主服务器是NameNode，从服务器是DataNode==。后面会讲到的Yarn、Spark等也都是这样的架构，这种一主多从的服务器架构也是绝大多数大数据系统的架构方案。。</p></li><li><p>Flume是对日志数据进行分布式收集，聚合和传输</p></li><li><p>Storm、Flink、Spark Streaming是实时计算</p></li><li><p>Mapreduce，spark是批计算，离线计算</p></li><li><p>NoSQL系统处理的主要也是大规模海量数据的存储与访问，例如hbase</p></li><li><p>大数据处理的主要应用场景包括数据分析、数据挖掘与机器学习。数据分析主要使用Hive、Spark SQL等SQL引擎完成；数据挖掘与机器学习则有专门的机器学习框架TensorFlow、Mahout以及MLlib等</p></li><li><p>HDFS：分布式文件系统</p></li><li><p>Hive可以在Hadoop上进行SQL操作，实现数据统计与分析<br><img src="https://static001.geekbang.org/resource/image/ca/73/ca6efc15ead7fb974caaa2478700f873.png" alt="image"></p></li><li><p>两台计算机要想合作构成一个系统，必须要在技术上重新架构。这就是现在互联网企业广泛使用的负载均衡、分布式缓存、分布式数据库、分布式服务等种种分布式系统</p></li><li><p>互联网应用系统架构中有一种重要架构原则是尽量使用无状态的服务，不同服务实例之间不共享状态，也就是不持有数据，用户请求交给任何一个服务实例计算，处理的结果都是一样的，为什么要这样设计？这种架构有什么好处？</p><p>答：便于扩容，无状态服务有利于提升分布式系统的可伸缩性</p></li><li><p>Hadoop中可以学到大数据领域的一个架构模式，==也就是集中管理，分布存储与计==算</p></li><li><p>Hive能够直接处理我们输入的SQL语句，调用MapReduce计算框架完成数据分析操作。</p></li><li><p>只要根据程序初始化好DAG，就建立了依赖关系，然后根据依赖关系顺序执行各个计算阶段，==Spark大数据应用的计算==就完成了</p></li><li><p>Spark==作业调度执行的核心是DA==G，有了DAG，整个应用就被切分成哪些阶段，每个阶段的依赖关系也就清楚了。之后再根据==每个阶段要处理的数据量生成相应的任务集合==（TaskSet），==每个任务都分配一个任务进程==去处理，Spark就实现了大数据的分布式计算</p></li><li><p>当RDD之间的==转换连接线呈现多对多交叉连接的时候，就会产生新的阶段==。一个==RDD代表一个数据集==，图中每个==RDD里面都包含多个小块==，每个==小块代表RDD的一个分片==。</p></li><li><p>==spark计算阶段划分的依据是shuffle，不是转换函数的类型==，有的函数有时候有shuffle，有时候没有</p></li><li><p>RDD里面的==每个数据分片==，Spark都会==创建一个计算任务去处==理，所以一个==计算阶段会包含很多个计算任务==（task）。</p></li><li><p>Spark支持Standalone、Yarn、Mesos、Kubernetes等多种部署方案</p></li><li><p>spark运行流程<br><img src="https://static001.geekbang.org/resource/image/16/db/164e9460133d7744d0315a876e7b6fdb.png" alt="image"><br>首先，Spark应用程序启动在自己的JVM进程里，即Driver进程，启动后调用SparkContext初始化执行配置和输入数据。SparkContext启动DAGScheduler构造执行的DAG图，切分成最小的执行单位也就是计算任务。</p><p>然后Driver向Cluster Manager请求计算资源，用于DAG的分布式计算。Cluster Manager收到请求以后，将Driver的主机地址等信息通知给集群的所有计算节点Worker。</p><p>Worker收到信息以后，根据Driver的主机地址，跟Driver通信并注册，然后根据自己的空闲资源向Driver通报自己可以领用的任务数。Driver根据DAG图开始向注册的Worker分配任务。</p><p>Worker收到任务后，启动Executor进程开始执行任务。Executor先检查自己是否有Driver的执行代码，如果没有，从Driver下载执行代码，通过Java反射加载后开始执行。<br><img src="https://static001.geekbang.org/resource/image/9f/ab/9fd982205b06ecd43053202da2ae08ab.png" alt="image"><br>HBase的核心设计目标是解决海量数据的分布式存储，和Memcached这类分布式缓存的路由算法不同，HBase的做法是按Key的区域进行分片，这个分片也就是HRegion。应用程序通过HMaster查找分片，得到HRegion所在的服务器HRegionServer，然后和该服务器通信，就得到了需要访问的数据。<br><img src="https://static001.geekbang.org/resource/image/fb/c3/fb535e9dc1813dbacfa03c7cb65d17c3.png" alt="image"><br>Spark Streaming巧妙地利用了Spark的分片和快速计算的特性，==将实时传输进来的数据按照时间进行分段，把一段时间传输进来的数据合并在一起，当作一批数据==，再去交给Spark去处理，Spark Streaming主要负责将流数据转换成小的批数据，剩下的就可以交给Spark去做了。</p></li><li><p>Flink处理实时数据流的方式跟Spark Streaming也很相似，==也是将流数据分段后，一小批一小批地处理==。流处理算是Flink里的“一等公民”，Flink对流处理的支持也更加完善，它可以对数据流执行window操作，将数据流切分到一个一个的window里，进而进行计算</p></li><li><p>==多台服务器状态一致性==的解决方案就是ZooKeeper，比如一个提供锁服务的分布式系统，它是由多台服务器构成一个集群对外提供锁服务，应用程序连接到任意一台服务器都可以获取或者释放锁，因此这些服务器必须严格保持状态一致，不能一台服务器将锁资源交给一个应用程序，而另一台服务器将锁资源交给另一个应用程序，所以像这种==分布式系统对数据一致性有更高的要求==。</p></li><li><p>大数据系统通常都是主从架构，主服务器==管理集群的状态和元信==息（meta-info），为了保证集群状态一致防止“脑裂”，所以运行期只能有一个主服务器工作（active master），但是为了==保证高可用，必须有另一个主服务器保持热备==（standby master</p></li><li><p>从应用角度讲，我们直接编写MapReduce或者Spark程序的机会并不多，通常我们会用Hive或者Spark SQL这样的大数据仓库工具进行大数据分析和计算。</p></li><li><p>性能优化：1. SQL语句优化。使用关系数据库的时候，SQL优化是数据库优化的重要手段，因为实现同样功能但是不同的SQL写法可能带来的性能差距是数量级的。我们知道在大数据分析时，由于数据量规模巨大，所以SQL语句写法引起的性能差距就更加巨大。典型的就是Hive的MapJoin语法，如果join的一张表比较小，比如只有几MB，那么就可以用MapJoin进行连接，Hive会将这张小表当作Cache数据全部加载到所有的Map任务中，在Map阶段完成join操作，无需shuffle。</p></li><li><p>数据倾斜处理。数据倾斜是指当两张表进行join的时候，其中一张表join的某个字段值对应的数据行数特别多，那么在shuffle的时候，这个字段值（Key）对应的所有记录都会被partition到同一个Reduce任务，导致这个任务长时间无法完成。淘宝的产品经理曾经讲过一个案例，他想把用户日志和用户表通过用户ID进行join，但是日志表有几亿条记录的用户ID是null，Hive把null当作一个字段值shuffle到同一个Reduce，结果这个Reduce跑了两天也没跑完，SQL当然也执行不完。像这种情况的数据倾斜，因为null字段没有意义，所以可以在where条件里加一个userID != null过滤掉就可以了</p></li><li><p>==HiBench==的价值不在于对各种大数据系统进行基准测试，而是学习大数据、验证自己大数据平台性能的工具。<br><img src="https://static001.geekbang.org/resource/image/5f/1f/5f0515ad5740575ff79ac8c68990071f.png" alt="image"><br>数据库同步通常用==Sqoop==或者Canal，日志同步可以选择F==lume==，打点采集的数据==经过格式化转换后通过Kafka等消息队列==进行传递。</p></li><li><p>前端埋点数据采集也是互联网应用大数据的重要来源之一，用户的某些前端行为并不会产生后端请求，比如用户在一个页面的停留时间、用户拖动页面的速度、用户选中一个复选框然后又取消（埋点的方式主要有手工埋点和自动化埋点。）</p></li><li><p>手工埋点就是前端开发者手动编程将需要采集的前端数据发送到后端的数据采集系统。通常公司会开发一些前端数据上报的SDK，前端工程师在需要埋点的地方，调用SDK，按照接口规范传入相关参数，比如ID、名称、页面、控件等通用参数，还有业务逻辑数据等，SDK将这些数据通过HTTP的方式发送到后端服务器。</p></li><li><p>自动化埋点则是通过一个前端程序SDK，自动收集全部用户操作事件，然后全量上传到后端服器。自动化埋点有时候也被称作无埋点，意思是无需埋点，实际上是全埋点，即全部用户操作都埋点采集。自动化埋点的好处是开发工作量小，数据规范统一。缺点是采集的数据量大，很多数据采集来也不知道有什么用，白白浪费了计算资源，特别是对于流量敏感的移动端用户而言，因为自动化埋点采集上传花费了大量的流量，可能因此成为卸载应用的理由，这样就得不偿失了。在实践中，有时候只是针对部分用户做自动埋点，抽样一部分数据做统计分析。</p></li><li><p>还有一种方案是可视化埋点。通过可视化的方式配置哪些前端操作需要埋点，根据配置采集数据。可视化埋点实际上是可以人工干预的自动化埋点。<br><img src="https://static001.geekbang.org/resource/image/d4/11/d4ad054351a04066650bd15d2dc28d11.png" alt="image"></p></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 科普 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据常见名词解释</title>
      <link href="/2019/11/07/hello-world/"/>
      <url>/2019/11/07/hello-world/</url>
      
        <content type="html"><![CDATA[<ol><li><p>Yarn 是主流的资源调度系统(Yarn是“Yet Another Resource Negotiator”的缩写，字面意思就是“==另一种资源调度器==”)</p></li><li><p>Yarn主要包括两个重要的部分，一个是资源管理器(resource manager)，一个是节点管理器（node manager）。其中资源管理器进程负责集群上所有资源的调度管理，常部署在==单独的服务器==上，节点管理器进程负责具体服务器资源和任务管理。在==集群的每一台计算服务器上都会启动==，基本上跟==hdfs的datanode一起启动==。</p></li><li><p>shuffle:分布式计算需要将不同服务器的相关数据合并到一起进行下一步计算</p></li><li><p>==MapReduce的主服务器就是JobTracker，从服务器就是TaskTracker==。还记得我们讲HDFS也是主从架构吗，==HDFS的主服务器是NameNode，从服务器是DataNode==。后面会讲到的Yarn、Spark等也都是这样的架构，这种一主多从的服务器架构也是绝大多数大数据系统的架构方案。。</p></li><li><p>Flume是对日志数据进行分布式收集，聚合和传输</p></li><li><p>Storm、Flink、Spark Streaming是实时计算</p></li><li><p>Mapreduce，spark是批计算，离线计算</p></li><li><p>NoSQL系统处理的主要也是大规模海量数据的存储与访问，例如hbase</p></li><li><p>大数据处理的主要应用场景包括数据分析、数据挖掘与机器学习。数据分析主要使用Hive、Spark SQL等SQL引擎完成；数据挖掘与机器学习则有专门的机器学习框架TensorFlow、Mahout以及MLlib等</p></li><li><p>HDFS：分布式文件系统</p></li><li><p>Hive可以在Hadoop上进行SQL操作，实现数据统计与分析<br><img src="https://static001.geekbang.org/resource/image/ca/73/ca6efc15ead7fb974caaa2478700f873.png" alt="image"></p></li><li><p>两台计算机要想合作构成一个系统，必须要在技术上重新架构。这就是现在互联网企业广泛使用的负载均衡、分布式缓存、分布式数据库、分布式服务等种种分布式系统</p></li><li><p>互联网应用系统架构中有一种重要架构原则是尽量使用无状态的服务，不同服务实例之间不共享状态，也就是不持有数据，用户请求交给任何一个服务实例计算，处理的结果都是一样的，为什么要这样设计？这种架构有什么好处？</p><p>答：便于扩容，无状态服务有利于提升分布式系统的可伸缩性</p></li><li><p>Hadoop中可以学到大数据领域的一个架构模式，==也就是集中管理，分布存储与计==算</p></li><li><p>Hive能够直接处理我们输入的SQL语句，调用MapReduce计算框架完成数据分析操作。</p></li><li><p>只要根据程序初始化好DAG，就建立了依赖关系，然后根据依赖关系顺序执行各个计算阶段，==Spark大数据应用的计算==就完成了</p></li><li><p>Spark==作业调度执行的核心是DA==G，有了DAG，整个应用就被切分成哪些阶段，每个阶段的依赖关系也就清楚了。之后再根据==每个阶段要处理的数据量生成相应的任务集合==（TaskSet），==每个任务都分配一个任务进程==去处理，Spark就实现了大数据的分布式计算</p></li><li><p>当RDD之间的==转换连接线呈现多对多交叉连接的时候，就会产生新的阶段==。一个==RDD代表一个数据集==，图中每个==RDD里面都包含多个小块==，每个==小块代表RDD的一个分片==。</p></li><li><p>==spark计算阶段划分的依据是shuffle，不是转换函数的类型==，有的函数有时候有shuffle，有时候没有</p></li><li><p>RDD里面的==每个数据分片==，Spark都会==创建一个计算任务去处==理，所以一个==计算阶段会包含很多个计算任务==（task）。</p></li><li><p>Spark支持Standalone、Yarn、Mesos、Kubernetes等多种部署方案</p></li><li><p>spark运行流程<br><img src="https://static001.geekbang.org/resource/image/16/db/164e9460133d7744d0315a876e7b6fdb.png" alt="image"><br>首先，Spark应用程序启动在自己的JVM进程里，即Driver进程，启动后调用SparkContext初始化执行配置和输入数据。SparkContext启动DAGScheduler构造执行的DAG图，切分成最小的执行单位也就是计算任务。</p><p>然后Driver向Cluster Manager请求计算资源，用于DAG的分布式计算。Cluster Manager收到请求以后，将Driver的主机地址等信息通知给集群的所有计算节点Worker。</p><p>Worker收到信息以后，根据Driver的主机地址，跟Driver通信并注册，然后根据自己的空闲资源向Driver通报自己可以领用的任务数。Driver根据DAG图开始向注册的Worker分配任务。</p><p>Worker收到任务后，启动Executor进程开始执行任务。Executor先检查自己是否有Driver的执行代码，如果没有，从Driver下载执行代码，通过Java反射加载后开始执行。<br><img src="https://static001.geekbang.org/resource/image/9f/ab/9fd982205b06ecd43053202da2ae08ab.png" alt="image"><br>HBase的核心设计目标是解决海量数据的分布式存储，和Memcached这类分布式缓存的路由算法不同，HBase的做法是按Key的区域进行分片，这个分片也就是HRegion。应用程序通过HMaster查找分片，得到HRegion所在的服务器HRegionServer，然后和该服务器通信，就得到了需要访问的数据。<br><img src="https://static001.geekbang.org/resource/image/fb/c3/fb535e9dc1813dbacfa03c7cb65d17c3.png" alt="image"><br>Spark Streaming巧妙地利用了Spark的分片和快速计算的特性，==将实时传输进来的数据按照时间进行分段，把一段时间传输进来的数据合并在一起，当作一批数据==，再去交给Spark去处理，Spark Streaming主要负责将流数据转换成小的批数据，剩下的就可以交给Spark去做了。</p></li><li><p>Flink处理实时数据流的方式跟Spark Streaming也很相似，==也是将流数据分段后，一小批一小批地处理==。流处理算是Flink里的“一等公民”，Flink对流处理的支持也更加完善，它可以对数据流执行window操作，将数据流切分到一个一个的window里，进而进行计算</p></li><li><p>==多台服务器状态一致性==的解决方案就是ZooKeeper，比如一个提供锁服务的分布式系统，它是由多台服务器构成一个集群对外提供锁服务，应用程序连接到任意一台服务器都可以获取或者释放锁，因此这些服务器必须严格保持状态一致，不能一台服务器将锁资源交给一个应用程序，而另一台服务器将锁资源交给另一个应用程序，所以像这种==分布式系统对数据一致性有更高的要求==。</p></li><li><p>大数据系统通常都是主从架构，主服务器==管理集群的状态和元信==息（meta-info），为了保证集群状态一致防止“脑裂”，所以运行期只能有一个主服务器工作（active master），但是为了==保证高可用，必须有另一个主服务器保持热备==（standby master</p></li><li><p>从应用角度讲，我们直接编写MapReduce或者Spark程序的机会并不多，通常我们会用Hive或者Spark SQL这样的大数据仓库工具进行大数据分析和计算。</p></li><li><p>性能优化：1. SQL语句优化。使用关系数据库的时候，SQL优化是数据库优化的重要手段，因为实现同样功能但是不同的SQL写法可能带来的性能差距是数量级的。我们知道在大数据分析时，由于数据量规模巨大，所以SQL语句写法引起的性能差距就更加巨大。典型的就是Hive的MapJoin语法，如果join的一张表比较小，比如只有几MB，那么就可以用MapJoin进行连接，Hive会将这张小表当作Cache数据全部加载到所有的Map任务中，在Map阶段完成join操作，无需shuffle。</p></li><li><p>数据倾斜处理。数据倾斜是指当两张表进行join的时候，其中一张表join的某个字段值对应的数据行数特别多，那么在shuffle的时候，这个字段值（Key）对应的所有记录都会被partition到同一个Reduce任务，导致这个任务长时间无法完成。淘宝的产品经理曾经讲过一个案例，他想把用户日志和用户表通过用户ID进行join，但是日志表有几亿条记录的用户ID是null，Hive把null当作一个字段值shuffle到同一个Reduce，结果这个Reduce跑了两天也没跑完，SQL当然也执行不完。像这种情况的数据倾斜，因为null字段没有意义，所以可以在where条件里加一个userID != null过滤掉就可以了</p></li><li><p>==HiBench==的价值不在于对各种大数据系统进行基准测试，而是学习大数据、验证自己大数据平台性能的工具。<br><img src="https://static001.geekbang.org/resource/image/5f/1f/5f0515ad5740575ff79ac8c68990071f.png" alt="image"><br>数据库同步通常用==Sqoop==或者Canal，日志同步可以选择F==lume==，打点采集的数据==经过格式化转换后通过Kafka等消息队列==进行传递。</p></li><li><p>前端埋点数据采集也是互联网应用大数据的重要来源之一，用户的某些前端行为并不会产生后端请求，比如用户在一个页面的停留时间、用户拖动页面的速度、用户选中一个复选框然后又取消（埋点的方式主要有手工埋点和自动化埋点。）</p></li><li><p>手工埋点就是前端开发者手动编程将需要采集的前端数据发送到后端的数据采集系统。通常公司会开发一些前端数据上报的SDK，前端工程师在需要埋点的地方，调用SDK，按照接口规范传入相关参数，比如ID、名称、页面、控件等通用参数，还有业务逻辑数据等，SDK将这些数据通过HTTP的方式发送到后端服务器。</p></li><li><p>自动化埋点则是通过一个前端程序SDK，自动收集全部用户操作事件，然后全量上传到后端服器。自动化埋点有时候也被称作无埋点，意思是无需埋点，实际上是全埋点，即全部用户操作都埋点采集。自动化埋点的好处是开发工作量小，数据规范统一。缺点是采集的数据量大，很多数据采集来也不知道有什么用，白白浪费了计算资源，特别是对于流量敏感的移动端用户而言，因为自动化埋点采集上传花费了大量的流量，可能因此成为卸载应用的理由，这样就得不偿失了。在实践中，有时候只是针对部分用户做自动埋点，抽样一部分数据做统计分析。</p></li><li><p>还有一种方案是可视化埋点。通过可视化的方式配置哪些前端操作需要埋点，根据配置采集数据。可视化埋点实际上是可以人工干预的自动化埋点。<br><img src="https://static001.geekbang.org/resource/image/d4/11/d4ad054351a04066650bd15d2dc28d11.png" alt="image"></p></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 科普 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql</title>
      <link href="/2019/11/05/new-blog/"/>
      <url>/2019/11/05/new-blog/</url>
      
        <content type="html"><![CDATA[<h1 id="3-4-mysql"><a href="#3-4-mysql" class="headerlink" title="3.4. mysql"></a>3.4. mysql</h1><h2 id="字段规范"><a href="#字段规范" class="headerlink" title="字段规范"></a>字段规范</h2><h3 id="数值类型"><a href="#数值类型" class="headerlink" title="数值类型"></a>数值类型</h3><table><thead><tr><th>整数类型</th><th>字节</th><th>范围（有符号）</th><th>范围（无符号）</th><th>用途</th></tr></thead><tbody><tr><td>TINYINT</td><td>1 字节</td><td>(-128，127)</td><td>(0，255)</td><td>小整数值</td></tr><tr><td>SMALLINT</td><td>2 字节</td><td>(-32 768，32 767)</td><td>(0，65 535)</td><td>大整数值</td></tr><tr><td>MEDIUMINT</td><td>3 字节</td><td>(-8 388 608，8 388 607)</td><td>(0，16 777 215)</td><td>大整数值</td></tr><tr><td>INT或INTEGER</td><td>4 字节</td><td>(-2 147 483 648，2 147 483 647)</td><td>(0，4 294 967 295)</td><td>大整数值</td></tr><tr><td>BIGINT</td><td>8 字节</td><td>(-9 233 372 036 854 775 808，9 223 372 036 854 775 807)</td><td>(0，18 446 744 073 709 551 615)</td><td>极大整数值</td></tr><tr><td>FLOAT</td><td>4 字节</td><td>(-3.402 823 466 E+38，-1.175 494 351 E-38)，0，(1.175 494 351 E-38，3.402 823 466 351 E+38)</td><td>0，(1.175 494 351 E-38，3.402 823 466 E+38)</td><td>单精度浮点数值</td></tr><tr><td>DOUBLE</td><td>8 字节</td><td>(-1.797 693 134 862 315 7 E+308，-2.225 073 858 507 201 4 E-308)，0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308)</td><td>0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308)</td><td>双精度浮点数值</td></tr><tr><td>DECIMAL</td><td>对DECIMAL(M,D) ，如果M&gt;D，为M+2否则为D+2</td><td>依赖于M和D的值</td><td>依赖于M和D的值</td><td>小数值</td></tr></tbody></table><h3 id="日期和时间类型"><a href="#日期和时间类型" class="headerlink" title="日期和时间类型"></a>日期和时间类型</h3><table><thead><tr><th>类型</th><th>字节</th><th>范围</th><th>格式</th><th>用途</th></tr></thead><tbody><tr><td>DATE</td><td>3</td><td>1000-01-01/9999-12-31</td><td>YYYY-MM-DD</td><td>日期值</td></tr><tr><td>TIME</td><td>3</td><td>‘-838:59:59’/‘838:59:59’</td><td>HH:MM:SS</td><td>时间值或持续时间</td></tr><tr><td>YEAR</td><td>1</td><td>1901/2155</td><td>YYYY</td><td>年份值</td></tr><tr><td>DATETIME</td><td>8</td><td>1000-01-01 00:00:00/9999-12-31 23:59:59</td><td>YYYY-MM-DD HH:MM:SS</td><td>混合日期和时间值</td></tr><tr><td>TIMESTAMP</td><td>4</td><td>1970-01-01 00:00:00/2037 年某时</td><td>YYYYMMDD HHMMSS</td><td>混合日期和时间值，时间戳</td></tr></tbody></table><h3 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h3><table><thead><tr><th>类型</th><th>大小</th><th>用途</th></tr></thead><tbody><tr><td>CHAR</td><td>0-255字节</td><td>定长字符串</td></tr><tr><td>VARCHAR</td><td>0-65535 字节</td><td>变长字符串</td></tr><tr><td>TINYBLOB</td><td>0-255字节</td><td>不超过 255 个字符的二进制字符串</td></tr><tr><td>TINYTEXT</td><td>0-255字节</td><td>短文本字符串</td></tr><tr><td>BLOB</td><td>0-65 535字节</td><td>二进制形式的长文本数据</td></tr><tr><td>TEXT</td><td>0-65 535字节</td><td>长文本数据</td></tr><tr><td>MEDIUMBLOB</td><td>0-16 777 215字节</td><td>二进制形式的中等长度文本数据</td></tr><tr><td>MEDIUMTEXT</td><td>0-16 777 215字节</td><td>中等长度文本数据</td></tr><tr><td>LONGBLOB</td><td>0-4 294 967 295字节</td><td>二进制形式的极大文本数据</td></tr><tr><td>LONGTEXT</td><td>0-4 294 967 295字节</td><td>极大文本数据</td></tr></tbody></table><h2 id="操作规范"><a href="#操作规范" class="headerlink" title="操作规范"></a>操作规范</h2><ol><li>1、SQL语句必须使用预绑定操作，不允许用变量拼接SQL，例如：select name from user where level = :level</li><li>2、查询时如果确定只有一条记录，要加上limit 1，例如：select name from user where uid = :uid limit 1</li><li>3、每张表必须有一个自增字段“id”为 primary key</li><li>4、根据需求合理配置每个字段的数据类型和长度</li><li>5、只有插入操作的表必须要有 create_time 字段记录插入操作的时间，同时有插入和更新操作的表必须要有 create_time 和 update_time 分别记录插入操作的时间和更新操作的时间</li><li>6、每张表必须根据需求合理设置表索引</li><li>7、日志表只允许插入操作,不允许更新操作</li><li>8、尽量减少联表搜索的操作</li><li>9、所有线上活动项目的 DB 写操作必须为异步</li><li>10、所有 SQL 语句在上线前必须通过 explain 指令检查效率,并根据 explain 结果对SQL 语句进行优化<h2 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h2>统一采用Innodb作为存储引擎，MyISAM引擎在写入操作较多的情况下锁表是致命伤 如果你想了解更多关于Innodb的信息，可以阅读如下文章 <a href="http://imysql.com/2014/11/01/mysql-faq-convert-myisam-to-innodb-tips.shtml" target="_blank" rel="noopener">从MyISAM转到InnoDB需要注意什么</a><br><a href="http://imysql.com/2014/11/01/mysql-faq-convert-myisam-to-innodb-tips.shtml" target="_blank" rel="noopener">InnoDB事务隔离级别、行锁、死锁解读</a><h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2></li></ol><ul><li>每张表必须拥有主键唯一索引</li><li>合理的设置索引，比如微信用户表</li></ul><pre><code>+----------------+---------------------+------+-----+---------+----------------+| Field          | Type                | Null | Key | Default | Extra          |+----------------+---------------------+------+-----+---------+----------------+| id             | int(11) unsigned    | NO   | PRI | NULL    | auto_increment || app_id         | varchar(50)         | YES  | MUL | NULL    |                || openid         | varchar(50)         | NO   |     |         |                || subscribe      | tinyint(4) unsigned | NO   |     | NULL    |                || nickname       | tinyblob            | NO   |     | NULL    |                || sex            | tinyint(4)          | YES  |     | NULL    |                || language       | varchar(10)         | YES  |     | NULL    |                || city           | varchar(30)         | YES  |     | NULL    |                || province       | varchar(10)         | YES  |     | NULL    |                || country        | varchar(20)         | YES  |     | NULL    |                || headimgurl     | varchar(200)        | YES  |     | NULL    |                || subscribe_time | int(11)             | YES  |     | NULL    |                || unionid        | varchar(50)         | YES  |     | NULL    |                || update_time    | datetime            | YES  |     | NULL    |                || create_time    | datetime            | YES  |     | NULL    |                |+----------------+---------------------+------+-----+---------+----------------+</code></pre><p>其中app_id和openid根据微信文档说明可知一个openid在同一个公众号下一定是唯一的，这里就需要给app_id和openid添加联合唯一索引</p><pre><code>*************************** 2. row ***************************        Table: user_info   Non_unique: 0     Key_name: un_appid_openid Seq_in_index: 1  Column_name: app_id    Collation: A  Cardinality: 2     Sub_part: NULL       Packed: NULL         Null: YES   Index_type: BTREE      Comment:Index_comment:*************************** 3. row ***************************        Table: user_info   Non_unique: 0     Key_name: un_appid_openid Seq_in_index: 2  Column_name: openid    Collation: A  Cardinality: 7426     Sub_part: NULL       Packed: NULL         Null:   Index_type: BTREE      Comment:Index_comment:</code></pre><h2 id="如何合理的设置索引"><a href="#如何合理的设置索引" class="headerlink" title="如何合理的设置索引"></a>如何合理的设置索引</h2><p>一般情况下很容易从业务角度来建立基本的索引，比如需要根据user_name来查询用户信息，那么user_name就需要加上索引，如果需要了解你的sql是否需要添加索引，你可以执行如下语句</p><p><code>EXPLAIN select * from xnfjnhb_reward where hongbao_id = 1</code><br>结果</p><pre><code>+----+-------------+----------------+------+---------------+------+---------+------+--------+-------------+| id | select_type | table          | type | possible_keys | key  | key_len | ref  | rows   | Extra       |+----+-------------+----------------+------+---------------+------+---------+------+--------+-------------+|  1 | SIMPLE      | xnfjnhb_reward | ALL  | NULL          | NULL | NULL    | NULL | 182689 | Using where |+----+-------------+----------------+------+---------------+------+---------+------+--------+-------------+</code></pre><p>可以看到rows执行了182689行，Extra指明了Using where需要优化，type为ALL全表扫描</p><p>我们给hongbao_id添加一个索引然后在执行EXPLAIN</p><pre><code>*************************** 2. row ***************************        Table: xnfjnhb_reward   Non_unique: 1     Key_name: idx_hongbao_id Seq_in_index: 1  Column_name: hongbao_id    Collation: A  Cardinality: 183991     Sub_part: NULL       Packed: NULL         Null: YES   Index_type: BTREE      Comment:Index_comment:</code></pre><pre><code>+----+-------------+----------------+------+----------------+----------------+---------+-------+------+-------+| id | select_type | table          | type | possible_keys  | key            | key_len | ref   | rows | Extra |+----+-------------+----------------+------+----------------+----------------+---------+-------+------+-------+|  1 | SIMPLE      | xnfjnhb_reward | ref  | idx_hongbao_id | idx_hongbao_id | 5       | const |    1 | NULL  |+----+-------------+----------------+------+----------------+----------------+---------+-------+------+-------+</code></pre><p>可以看到type已经走了ref索引，rows瞬间变为了1，Extra也为NULL</p><blockquote><p>我举的这个例子可能并不能看到明显的性能提升，因为数据量还没有达到一定的级别，但是并不能因此就忽略了索引的重要性，因为如果是后期添加索引将是一件困难的事情</p><p>找到一个不太恰当的例子，假如真的有如下SQL语句来看看索引前后的查询速度差别</p></blockquote><pre><code>//索引前select count(*),hongbao_id from xnfjnhb_reward group by hongbao_id having count(*) &gt; 15180 rows in set (2.27 sec)</code></pre><pre><code>//索引后select count(*),hongbao_id from xnfjnhb_reward group by hongbao_id having count(*) &gt; 15180 rows in set (0.16 sec)</code></pre><p>更多优化技巧你可以阅读下面的文章 <a href="http://imysql.cn/node/35" target="_blank" rel="noopener">MySQL 优化EXPLAIN</a></p><h2 id="在PDO中使用Mysql证书"><a href="#在PDO中使用Mysql证书" class="headerlink" title="在PDO中使用Mysql证书"></a>在PDO中使用Mysql证书</h2><ul><li>如果项目中操作数据库有安全性要求，例如要求连接mysql时必须使用证书，那么就需要在使用PDO时，添加相应的配置项。</li><li></li><li>其中着重注意，如果证书是由服务器端自生成的，那么有可能会引起连接过程中无法验证证书，处理方法类似curl请求https时，忽略证书验证的方法。 而且PDO连接数据库时需要忽略证书的选项(PDO::MYSQL_ATTR_SSL_VERIFY_SERVER_CERT)并没有明文写在PHP官方手册中，而是在手册的评论中被指出：</li></ul><pre><code>There is an important undocumented attribute which disables certificate CN verification available after5.6.22 (not sure), 7.0.18 (verified) and 7.1.15 (not sure)PDO::MYSQL_ATTR_SSL_VERIFY_SERVER_CERTpossible values: true, falsedefault value: true Related PHP bugs:https://bugs.php.net/bug.php?id=71845https://bugs.php.net/bug.php?id=71003and github PR: https://github.com/php/php-src/pull/1913</code></pre><p>综上，示例配置如下：</p><p>yaf项目请修改library/DB.php文件，参考配置如下：</p><pre><code>$options = ENVIRONMENT != 'develop' ? [        PDO::MYSQL_ATTR_SSL_KEY   =&gt; APPLICATION_PATH."/ssl/".ENVIRONMENT.'/client-key.pem',        PDO::MYSQL_ATTR_SSL_CERT  =&gt; APPLICATION_PATH."/ssl/".ENVIRONMENT.'/client-cert.pem',        PDO::MYSQL_ATTR_SSL_CA    =&gt; APPLICATION_PATH."/ssl/".ENVIRONMENT.'/cacert.pem',        PDO::MYSQL_ATTR_SSL_VERIFY_SERVER_CERT =&gt; false,        PDO::ATTR_TIMEOUT =&gt; 1    ] : [ PDO::ATTR_TIMEOUT =&gt;1 ];$db = new PDO('mysql:host='.$db_config-&gt;host.';dbname='.$db_config-&gt;database, $db_config-&gt;username, $db_config-&gt;password,$options);</code></pre><p>laravel项目请修改config/database.php文件，参考配置如下：</p><pre><code>'mysql' =&gt; [    'driver'      =&gt; 'mysql',    'host'        =&gt; env('DB_HOST', '127.0.0.1'),    'port'        =&gt; env('DB_PORT', '3306'),    'database'    =&gt; env('DB_DATABASE', ''),    'username'    =&gt; env('DB_USERNAME', ''),    'password'    =&gt; env('DB_PASSWORD', ''),    'unix_socket' =&gt; env('DB_SOCKET', ''),    'charset'     =&gt; 'utf8mb4',    'collation'   =&gt; 'utf8mb4_unicode_ci',    'prefix'      =&gt; '',    'strict'      =&gt; true,    'engine'      =&gt; null,    'options'     =&gt; ENVIRONMENT != 'develop'?[        PDO::MYSQL_ATTR_SSL_KEY   =&gt; base_path("ssl/".ENVIRONMENT.'/client-key.pem'),        PDO::MYSQL_ATTR_SSL_CERT  =&gt; base_path("ssl/".ENVIRONMENT.'/client-cert.pem'),        PDO::MYSQL_ATTR_SSL_CA    =&gt; base_path("ssl/".ENVIRONMENT.'/cacert.pem'),        PDO::MYSQL_ATTR_SSL_VERIFY_SERVER_CERT =&gt; false        PDO::ATTR_TIMEOUT =&gt; 1    ] : [ PDO::ATTR_TIMEOUT =&gt; 1 ];],</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>推荐系统</title>
      <link href="/2019/11/05/tuijian-system/"/>
      <url>/2019/11/05/tuijian-system/</url>
      
        <content type="html"><![CDATA[<h1 id="推荐系统"><a href="#推荐系统" class="headerlink" title="推荐系统"></a>推荐系统</h1><ul><li><h3 id="推荐算法的本质是通过一定的方式将用户和物品联系起来，而不同的推荐系统利用了不同的方式"><a href="#推荐算法的本质是通过一定的方式将用户和物品联系起来，而不同的推荐系统利用了不同的方式" class="headerlink" title="推荐算法的本质是通过一定的方式将用户和物品联系起来，而不同的推荐系统利用了不同的方式"></a>推荐算法的本质是通过一定的方式将用户和物品联系起来，而不同的推荐系统利用了不同的方式</h3></li><li><h3 id="在信息过载的环境中帮助用户发现令他们感兴趣的信息，也能将信息推送给对它们感兴趣的用户"><a href="#在信息过载的环境中帮助用户发现令他们感兴趣的信息，也能将信息推送给对它们感兴趣的用户" class="headerlink" title="在信息过载的环境中帮助用户发现令他们感兴趣的信息，也能将信息推送给对它们感兴趣的用户"></a>在信息过载的环境中帮助用户发现令他们感兴趣的信息，也能将信息推送给对它们感兴趣的用户</h3></li></ul><h2 id="1-推荐系统的应用"><a href="#1-推荐系统的应用" class="headerlink" title="1.推荐系统的应用"></a>1.推荐系统的应用</h2><blockquote><h4 id="电子商务"><a href="#电子商务" class="headerlink" title="电子商务:"></a>电子商务:</h4><p>亚马逊<br>基于物品的推荐 好友关系推荐 相关推荐(购买过该产品的用户也够买过其他的，浏览过该商品的也浏览过其他）</p></blockquote><blockquote><h4 id="电影和视频网站"><a href="#电影和视频网站" class="headerlink" title="电影和视频网站"></a>电影和视频网站</h4><p>Netflix YouTube 基于物品推荐</p></blockquote><blockquote><h4 id="个性化音乐网络电台"><a href="#个性化音乐网络电台" class="headerlink" title="个性化音乐网络电台"></a>个性化音乐网络电台</h4><p>pandora基于内容推荐， 歌曲的旋律节奏，编曲和歌词进行标注，标注称为音乐基因，计算歌曲相似度给用户推荐<br>last.fm 计算不同用户在歌曲上喜好相似度，给用户推荐和他有相似喜好的用户喜欢的歌 基于用户行为</p></blockquote><blockquote><h4 id="社交网络"><a href="#社交网络" class="headerlink" title="社交网络"></a>社交网络</h4><p>好友的行为推荐给用户， 好友推荐</p></blockquote><blockquote><h4 id="个性化阅读"><a href="#个性化阅读" class="headerlink" title="个性化阅读"></a>个性化阅读</h4><p>基于内容和基于相似用户的喜好</p></blockquote><blockquote><h4 id="基于位置的服务"><a href="#基于位置的服务" class="headerlink" title="基于位置的服务"></a>基于位置的服务</h4><p>地图定位，搜索附近</p></blockquote><blockquote><h4 id="个性化邮件"><a href="#个性化邮件" class="headerlink" title="个性化邮件"></a>个性化邮件</h4><p>基于内容</p></blockquote><blockquote><h4 id="个性化广告"><a href="#个性化广告" class="headerlink" title="个性化广告"></a>个性化广告</h4><p>上下文广告：分析用户正在浏览的网页内容，推荐和网页内容相关的广告 谷歌Adsense<br>搜索广告：通过分析用户在当前会话中的搜索记录，判断用户的搜索目的，投放广告<br>个性化展示广告：不同的用户展示不同的广告</p></blockquote><h2 id="2-推荐系统的评测"><a href="#2-推荐系统的评测" class="headerlink" title="2.推荐系统的评测"></a>2.推荐系统的评测</h2><blockquote><h4 id="满意度：用户满意度-问卷调查"><a href="#满意度：用户满意度-问卷调查" class="headerlink" title="满意度：用户满意度(问卷调查)"></a>满意度：用户满意度(问卷调查)</h4><h4 id="预测准确度：均方根误差RMSE-平均绝对误差MAE，topn推荐-混淆矩阵"><a href="#预测准确度：均方根误差RMSE-平均绝对误差MAE，topn推荐-混淆矩阵" class="headerlink" title="预测准确度：均方根误差RMSE,平均绝对误差MAE，topn推荐(混淆矩阵)"></a>预测准确度：均方根误差RMSE,平均绝对误差MAE，topn推荐(混淆矩阵)</h4><h4 id="覆盖率：描述对物品长尾的发掘能力，推荐系统推荐的列表占总物品的比例-信息熵和基尼系数"><a href="#覆盖率：描述对物品长尾的发掘能力，推荐系统推荐的列表占总物品的比例-信息熵和基尼系数" class="headerlink" title="覆盖率：描述对物品长尾的发掘能力，推荐系统推荐的列表占总物品的比例(信息熵和基尼系数)"></a>覆盖率：描述对物品长尾的发掘能力，推荐系统推荐的列表占总物品的比例(信息熵和基尼系数)</h4><h4 id="多样性：基于不同相似度的计算推荐不同的多样性列表-基于内容，基于协同过滤"><a href="#多样性：基于不同相似度的计算推荐不同的多样性列表-基于内容，基于协同过滤" class="headerlink" title="多样性：基于不同相似度的计算推荐不同的多样性列表(基于内容，基于协同过滤)"></a>多样性：基于不同相似度的计算推荐不同的多样性列表(基于内容，基于协同过滤)</h4><h4 id="新颖性：推荐用户没有听过的商物品-例如用户喜欢动作类型的电影，给用户推荐了一部从来没有听说过的也属于动作类型的电影"><a href="#新颖性：推荐用户没有听过的商物品-例如用户喜欢动作类型的电影，给用户推荐了一部从来没有听说过的也属于动作类型的电影" class="headerlink" title="新颖性：推荐用户没有听过的商物品(例如用户喜欢动作类型的电影，给用户推荐了一部从来没有听说过的也属于动作类型的电影)"></a>新颖性：推荐用户没有听过的商物品(例如用户喜欢动作类型的电影，给用户推荐了一部从来没有听说过的也属于动作类型的电影)</h4><h4 id="惊喜度：推荐个用户兴趣之外的物品给用户，用户觉得非常满意，代表惊喜度很高"><a href="#惊喜度：推荐个用户兴趣之外的物品给用户，用户觉得非常满意，代表惊喜度很高" class="headerlink" title="惊喜度：推荐个用户兴趣之外的物品给用户，用户觉得非常满意，代表惊喜度很高"></a>惊喜度：推荐个用户兴趣之外的物品给用户，用户觉得非常满意，代表惊喜度很高</h4><h4 id="信任度：度量推荐系统的信任度只能通过调查问卷，可以通过增加推荐系统透明度来提高信任度-例如让用户了解推荐系统的运行机制，其次通过好友的信息来推荐，并用好友做推荐解释，让用户对推荐系统有认同感"><a href="#信任度：度量推荐系统的信任度只能通过调查问卷，可以通过增加推荐系统透明度来提高信任度-例如让用户了解推荐系统的运行机制，其次通过好友的信息来推荐，并用好友做推荐解释，让用户对推荐系统有认同感" class="headerlink" title="信任度：度量推荐系统的信任度只能通过调查问卷，可以通过增加推荐系统透明度来提高信任度(例如让用户了解推荐系统的运行机制，其次通过好友的信息来推荐，并用好友做推荐解释，让用户对推荐系统有认同感)"></a>信任度：度量推荐系统的信任度只能通过调查问卷，可以通过增加推荐系统透明度来提高信任度(例如让用户了解推荐系统的运行机制，其次通过好友的信息来推荐，并用好友做推荐解释，让用户对推荐系统有认同感)</h4><h4 id="实时性：新闻，微博，用户推荐列表中有多大比例的物品是当天新加"><a href="#实时性：新闻，微博，用户推荐列表中有多大比例的物品是当天新加" class="headerlink" title="实时性：新闻，微博，用户推荐列表中有多大比例的物品是当天新加"></a>实时性：新闻，微博，用户推荐列表中有多大比例的物品是当天新加</h4><h4 id="健壮性：抗作弊，例如用户购买A后，也经常购买其他商品，这里是统计购买其他商品的次数来推荐，这样可以注册很多账号，购买A后同时购买这个商品，提高次数。针对评分系统，刷评分。给定一个数据集和算法，生成推荐列表，然后向数据中加入噪声数据，生成噪声推荐列表，看是否发生大的变化"><a href="#健壮性：抗作弊，例如用户购买A后，也经常购买其他商品，这里是统计购买其他商品的次数来推荐，这样可以注册很多账号，购买A后同时购买这个商品，提高次数。针对评分系统，刷评分。给定一个数据集和算法，生成推荐列表，然后向数据中加入噪声数据，生成噪声推荐列表，看是否发生大的变化" class="headerlink" title="健壮性：抗作弊，例如用户购买A后，也经常购买其他商品，这里是统计购买其他商品的次数来推荐，这样可以注册很多账号，购买A后同时购买这个商品，提高次数。针对评分系统，刷评分。给定一个数据集和算法，生成推荐列表，然后向数据中加入噪声数据，生成噪声推荐列表，看是否发生大的变化"></a>健壮性：抗作弊，例如用户购买A后，也经常购买其他商品，这里是统计购买其他商品的次数来推荐，这样可以注册很多账号，购买A后同时购买这个商品，提高次数。针对评分系统，刷评分。给定一个数据集和算法，生成推荐列表，然后向数据中加入噪声数据，生成噪声推荐列表，看是否发生大的变化</h4><h4 id="商业目标：一个用户给公司带来的利益-销售额，广告展示总数，广告点击数等"><a href="#商业目标：一个用户给公司带来的利益-销售额，广告展示总数，广告点击数等" class="headerlink" title="商业目标：一个用户给公司带来的利益(销售额，广告展示总数，广告点击数等)"></a>商业目标：一个用户给公司带来的利益(销售额，广告展示总数，广告点击数等)</h4><p><img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190613/5f2ac1e0e6ba88b3e587d5275a2d48b6.png" alt="file"></p></blockquote><h2 id="3-利用用户行为数据"><a href="#3-利用用户行为数据" class="headerlink" title="3.利用用户行为数据"></a>3.利用用户行为数据</h2><blockquote><h4 id="日志分析：网页浏览，购买，点击，评分，评论等"><a href="#日志分析：网页浏览，购买，点击，评分，评论等" class="headerlink" title="日志分析：网页浏览，购买，点击，评分，评论等"></a>日志分析：网页浏览，购买，点击，评分，评论等</h4><p>显性反馈：明确表示对物品的喜好行为(喜欢/不喜欢，评分1-5)<br>隐性反馈：不能明确反应用户的喜好行为(浏览，购买，观看，阅读，听歌)<br>反馈方式：正向反馈和负向反馈</p><blockquote><p><img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190613/36c8c6a81a074613ee9c58b15066978a.png" alt="file"></p></blockquote></blockquote><blockquote><h4 id="用户行为分析"><a href="#用户行为分析" class="headerlink" title="用户行为分析"></a>用户行为分析</h4><h6 id="用户活跃度和物品流行度都满足长尾分布"><a href="#用户活跃度和物品流行度都满足长尾分布" class="headerlink" title="用户活跃度和物品流行度都满足长尾分布"></a>用户活跃度和物品流行度都满足长尾分布</h6><h6 id="长尾分布：作为全球排名第一的购物网站，亚马逊拥有超高的图书销售量，尤其是长尾产品描述。“搜索引擎指南”发现，亚马逊通过长尾搜索产生了57％的销售额"><a href="#长尾分布：作为全球排名第一的购物网站，亚马逊拥有超高的图书销售量，尤其是长尾产品描述。“搜索引擎指南”发现，亚马逊通过长尾搜索产生了57％的销售额" class="headerlink" title="长尾分布：作为全球排名第一的购物网站，亚马逊拥有超高的图书销售量，尤其是长尾产品描述。“搜索引擎指南”发现，亚马逊通过长尾搜索产生了57％的销售额"></a>长尾分布：作为全球排名第一的购物网站，亚马逊拥有超高的图书销售量，尤其是长尾产品描述。“搜索引擎指南”发现，亚马逊通过长尾搜索产生了57％的销售额</h6><p><img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190613/55ae3048e81689df01d7f51d2b935170.png" alt="file"></p><h6 id="用户活跃度和物品流行度的关系：越活跃的用户浏览会逐渐浏览冷门的物品"><a href="#用户活跃度和物品流行度的关系：越活跃的用户浏览会逐渐浏览冷门的物品" class="headerlink" title="用户活跃度和物品流行度的关系：越活跃的用户浏览会逐渐浏览冷门的物品"></a>用户活跃度和物品流行度的关系：越活跃的用户浏览会逐渐浏览冷门的物品</h6><h6 id="协同过滤算法：基于邻域的方法，隐语义模型，基于图的随机游走。基于邻域的只要包含基于用户和物品的协同过滤，一个是计算用户间的相似度，一个是计算物品间的相似度。"><a href="#协同过滤算法：基于邻域的方法，隐语义模型，基于图的随机游走。基于邻域的只要包含基于用户和物品的协同过滤，一个是计算用户间的相似度，一个是计算物品间的相似度。" class="headerlink" title="协同过滤算法：基于邻域的方法，隐语义模型，基于图的随机游走。基于邻域的只要包含基于用户和物品的协同过滤，一个是计算用户间的相似度，一个是计算物品间的相似度。"></a>协同过滤算法：基于邻域的方法，隐语义模型，基于图的随机游走。基于邻域的只要包含基于用户和物品的协同过滤，一个是计算用户间的相似度，一个是计算物品间的相似度。</h6></blockquote><blockquote><h4 id="基于用户相似度的协同过滤"><a href="#基于用户相似度的协同过滤" class="headerlink" title="基于用户相似度的协同过滤"></a>基于用户相似度的协同过滤</h4><p><img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190613/759db5de96947d4e617a04e1701f5c29.png" alt="file"></p><h6 id="Jaccard公式"><a href="#Jaccard公式" class="headerlink" title="Jaccard公式:"></a>Jaccard公式:<img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190613/1e14389954d7522faf7d472db36ab5a0.png" alt="file"></h6><h6 id="余弦相似度："><a href="#余弦相似度：" class="headerlink" title="余弦相似度："></a>余弦相似度：<img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190613/3399303cbb2c3b7ccd30d6c9048ed562.png" alt="file"></h6><h6 id="用户A和用户B的兴趣相似度："><a href="#用户A和用户B的兴趣相似度：" class="headerlink" title="用户A和用户B的兴趣相似度："></a>用户A和用户B的兴趣相似度：<img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190613/a3551e3a36663a45fb082a6917157dad.png" alt="file"></h6><h6 id="由于对两两用户计算相似度非常耗时，而且很多用户之前没有对同样对物品产生行为，这里对数据集进行了处理，算出一个倒排表，表里对两个用户对应的值是余弦相似度的分子。"><a href="#由于对两两用户计算相似度非常耗时，而且很多用户之前没有对同样对物品产生行为，这里对数据集进行了处理，算出一个倒排表，表里对两个用户对应的值是余弦相似度的分子。" class="headerlink" title="由于对两两用户计算相似度非常耗时，而且很多用户之前没有对同样对物品产生行为，这里对数据集进行了处理，算出一个倒排表，表里对两个用户对应的值是余弦相似度的分子。"></a>由于对两两用户计算相似度非常耗时，而且很多用户之前没有对同样对物品产生行为，这里对数据集进行了处理，算出一个倒排表，表里对两个用户对应的值是余弦相似度的分子。</h6><h6 id="得到用户之间的兴趣相似度后，UserCF算法会给用户推荐和他兴趣最相似的K个用户喜欢的物品。如下的公式度量了UserCF算法中用户u对物品i的感兴趣程度"><a href="#得到用户之间的兴趣相似度后，UserCF算法会给用户推荐和他兴趣最相似的K个用户喜欢的物品。如下的公式度量了UserCF算法中用户u对物品i的感兴趣程度" class="headerlink" title="得到用户之间的兴趣相似度后，UserCF算法会给用户推荐和他兴趣最相似的K个用户喜欢的物品。如下的公式度量了UserCF算法中用户u对物品i的感兴趣程度:"></a>得到用户之间的兴趣相似度后，UserCF算法会给用户推荐和他兴趣最相似的K个用户喜欢的物品。如下的公式度量了UserCF算法中用户u对物品i的感兴趣程度:<img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190613/21e79a404299218adabe69b887e9f59d.png" alt="file"></h6><h6 id="其中，S-u-K-包含和用户u兴趣最接近的K个用户，N-i-是对物品i有过行为的用户集合，wuv-是用户u和用户v的兴趣相似度，rvi代表用户v对物品i的兴趣，因为使用的是单一行为的隐反馈数-据，所以所有的rvi-1"><a href="#其中，S-u-K-包含和用户u兴趣最接近的K个用户，N-i-是对物品i有过行为的用户集合，wuv-是用户u和用户v的兴趣相似度，rvi代表用户v对物品i的兴趣，因为使用的是单一行为的隐反馈数-据，所以所有的rvi-1" class="headerlink" title="其中，S(u, K)包含和用户u兴趣最接近的K个用户，N(i)是对物品i有过行为的用户集合，wuv 是用户u和用户v的兴趣相似度，rvi代表用户v对物品i的兴趣，因为使用的是单一行为的隐反馈数 据，所以所有的rvi=1"></a>其中，S(u, K)包含和用户u兴趣最接近的K个用户，N(i)是对物品i有过行为的用户集合，wuv 是用户u和用户v的兴趣相似度，rvi代表用户v对物品i的兴趣，因为使用的是单一行为的隐反馈数 据，所以所有的rvi=1</h6><h6 id="这里取k-3-与A兴趣最接近的三个用户，A用户对c-e没有过行为，把这两个物品推荐给用户A"><a href="#这里取k-3-与A兴趣最接近的三个用户，A用户对c-e没有过行为，把这两个物品推荐给用户A" class="headerlink" title="这里取k=3,与A兴趣最接近的三个用户，A用户对c,e没有过行为，把这两个物品推荐给用户A"></a>这里取k=3,与A兴趣最接近的三个用户，A用户对c,e没有过行为，把这两个物品推荐给用户A</h6><p><img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190613/fd9074ecf8b3bcf1d12ccd11987dd785.png" alt="file"></p><h6 id="用户相似度的改进，增加了惩罚项，这个的N-i-书中没有说是什么值，只说了惩罚了用户u和用户v共同兴趣列表中热门物品对他们相似度的影响，所以这个值猜测跟上面一样，喜欢物品i的用户有多少即物品的热门程度"><a href="#用户相似度的改进，增加了惩罚项，这个的N-i-书中没有说是什么值，只说了惩罚了用户u和用户v共同兴趣列表中热门物品对他们相似度的影响，所以这个值猜测跟上面一样，喜欢物品i的用户有多少即物品的热门程度" class="headerlink" title="用户相似度的改进，增加了惩罚项，这个的N(i)书中没有说是什么值，只说了惩罚了用户u和用户v共同兴趣列表中热门物品对他们相似度的影响，所以这个值猜测跟上面一样，喜欢物品i的用户有多少即物品的热门程度"></a>用户相似度的改进，增加了惩罚项，这个的N(i)书中没有说是什么值，只说了惩罚了用户u和用户v共同兴趣列表中热门物品对他们相似度的影响，所以这个值猜测跟上面一样，喜欢物品i的用户有多少即物品的热门程度</h6><p><img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190613/1e25efc40205d128e16113fb88c061da.png" alt="file"></p></blockquote><blockquote><h4 id="基于物品的协同过滤"><a href="#基于物品的协同过滤" class="headerlink" title="基于物品的协同过滤"></a>基于物品的协同过滤</h4><h6 id="这里基于物品的相似计算和基于用户的类似"><a href="#这里基于物品的相似计算和基于用户的类似" class="headerlink" title="这里基于物品的相似计算和基于用户的类似"></a>这里基于物品的相似计算和基于用户的类似</h6><p><img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190613/2ee5e4397f4b43d4070bf7e0b2a37b72.png" alt="file"><br><img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190613/87a7428bb5fe5d85da478cb6edb20d94.png" alt="file"></p><h6 id="上面这个表算出的是余弦相似度的分子。这里N-u-是用户喜欢的物品的集合，S-j-K-是和物品j最相似的K个物品的集合，wji是物品j和i-的相似度，rui是用户u对物品i的兴趣"><a href="#上面这个表算出的是余弦相似度的分子。这里N-u-是用户喜欢的物品的集合，S-j-K-是和物品j最相似的K个物品的集合，wji是物品j和i-的相似度，rui是用户u对物品i的兴趣" class="headerlink" title="上面这个表算出的是余弦相似度的分子。这里N(u)是用户喜欢的物品的集合，S(j,K)是和物品j最相似的K个物品的集合，wji是物品j和i 的相似度，rui是用户u对物品i的兴趣"></a>上面这个表算出的是余弦相似度的分子。这里N(u)是用户喜欢的物品的集合，S(j,K)是和物品j最相似的K个物品的集合，wji是物品j和i 的相似度，rui是用户u对物品i的兴趣<img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190613/e6bb37e85701940581bb654aeb1f15b4.png" alt="file"></h6><h6 id="基于物品和用户的推荐比较"><a href="#基于物品和用户的推荐比较" class="headerlink" title="基于物品和用户的推荐比较"></a>基于物品和用户的推荐比较</h6><p><img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190614/6298dce8df0e048dfb008884353a2052.png" alt="file"></p></blockquote><blockquote><h4 id="隐语意模型"><a href="#隐语意模型" class="headerlink" title="隐语意模型"></a>隐语意模型</h4><h6 id="隐语意模型主要是找到用户和物品的隐含关系"><a href="#隐语意模型主要是找到用户和物品的隐含关系" class="headerlink" title="隐语意模型主要是找到用户和物品的隐含关系"></a>隐语意模型主要是找到用户和物品的隐含关系</h6></blockquote><blockquote><h4 id="基于图的推荐"><a href="#基于图的推荐" class="headerlink" title="基于图的推荐"></a>基于图的推荐</h4><h6 id="假设用户和物品在空间中生成了一张二部图，图中的顶点分为用户和物品两个子集，图中的边是用户和物品的行为，用图做推荐，其实就是计算两个顶点之间的相关性。"><a href="#假设用户和物品在空间中生成了一张二部图，图中的顶点分为用户和物品两个子集，图中的边是用户和物品的行为，用图做推荐，其实就是计算两个顶点之间的相关性。" class="headerlink" title="假设用户和物品在空间中生成了一张二部图，图中的顶点分为用户和物品两个子集，图中的边是用户和物品的行为，用图做推荐，其实就是计算两个顶点之间的相关性。"></a>假设用户和物品在空间中生成了一张二部图，图中的顶点分为用户和物品两个子集，图中的边是用户和物品的行为，用图做推荐，其实就是计算两个顶点之间的相关性。</h6><h6 id="一般图中顶点的相关性主要取决于："><a href="#一般图中顶点的相关性主要取决于：" class="headerlink" title="一般图中顶点的相关性主要取决于："></a>一般图中顶点的相关性主要取决于：</h6><ul><li><h6 id="两个顶点之间的路径数"><a href="#两个顶点之间的路径数" class="headerlink" title="两个顶点之间的路径数"></a>两个顶点之间的路径数</h6></li><li><h6 id="两个顶点之间的长度"><a href="#两个顶点之间的长度" class="headerlink" title="两个顶点之间的长度"></a>两个顶点之间的长度</h6></li><li><h6 id="两个顶点之间的路径经过的顶点"><a href="#两个顶点之间的路径经过的顶点" class="headerlink" title="两个顶点之间的路径经过的顶点"></a>两个顶点之间的路径经过的顶点</h6></li></ul><h6 id="相关性高的一对顶点一般有如下特征："><a href="#相关性高的一对顶点一般有如下特征：" class="headerlink" title="相关性高的一对顶点一般有如下特征："></a>相关性高的一对顶点一般有如下特征：</h6><ul><li><h6 id="两个顶点之间有很多路径相连"><a href="#两个顶点之间有很多路径相连" class="headerlink" title="两个顶点之间有很多路径相连"></a>两个顶点之间有很多路径相连</h6></li><li><h6 id="连接两个顶点之间的路径长度都比较短"><a href="#连接两个顶点之间的路径长度都比较短" class="headerlink" title="连接两个顶点之间的路径长度都比较短"></a>连接两个顶点之间的路径长度都比较短</h6></li><li><h6 id="连接两个顶点之间的路径不会经过度比较大的顶点-度就是与这个顶点相关联的边数"><a href="#连接两个顶点之间的路径不会经过度比较大的顶点-度就是与这个顶点相关联的边数" class="headerlink" title="连接两个顶点之间的路径不会经过度比较大的顶点(度就是与这个顶点相关联的边数)"></a>连接两个顶点之间的路径不会经过度比较大的顶点(度就是与这个顶点相关联的边数)</h6><img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190618/258fcc94742fe3816dbd19d786dc0480.png" alt="file"><h6 id="这里拿A点来举例，给A推荐没有过交互的物品c和e，A和c有一条路径相连-A-d-D-c-，A和e有两条路径相连-A-b-C-e-A-d-D-e-，所以物品e的相关性比较高。A和e的第一条路径里每个顶点的边数为-3-2-2-2-第二条路径为-3-2-3-2-，所以第一条路径对A和e相关性的贡献较高。"><a href="#这里拿A点来举例，给A推荐没有过交互的物品c和e，A和c有一条路径相连-A-d-D-c-，A和e有两条路径相连-A-b-C-e-A-d-D-e-，所以物品e的相关性比较高。A和e的第一条路径里每个顶点的边数为-3-2-2-2-第二条路径为-3-2-3-2-，所以第一条路径对A和e相关性的贡献较高。" class="headerlink" title="这里拿A点来举例，给A推荐没有过交互的物品c和e，A和c有一条路径相连(A,d,D,c)，A和e有两条路径相连(A,b,C,e),(A,d,D,e)，所以物品e的相关性比较高。A和e的第一条路径里每个顶点的边数为(3,2,2,2),第二条路径为(3,2,3,2)，所以第一条路径对A和e相关性的贡献较高。"></a>这里拿A点来举例，给A推荐没有过交互的物品c和e，A和c有一条路径相连(A,d,D,c)，A和e有两条路径相连(A,b,C,e),(A,d,D,e)，所以物品e的相关性比较高。A和e的第一条路径里每个顶点的边数为(3,2,2,2),第二条路径为(3,2,3,2)，所以第一条路径对A和e相关性的贡献较高。</h6><h6 id="pagerank：http-blog-jobbole-com-71431"><a href="#pagerank：http-blog-jobbole-com-71431" class="headerlink" title="pagerank：http://blog.jobbole.com/71431/"></a>pagerank：<a href="http://blog.jobbole.com/71431/" target="_blank" rel="noopener">http://blog.jobbole.com/71431/</a></h6><h6 id="personalrank：https-cloud-tencent-com-developer-article-1098856"><a href="#personalrank：https-cloud-tencent-com-developer-article-1098856" class="headerlink" title="personalrank：https://cloud.tencent.com/developer/article/1098856"></a>personalrank：<a href="https://cloud.tencent.com/developer/article/1098856" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1098856</a></h6></li></ul></blockquote><h2 id="4-推荐系统冷启动问题"><a href="#4-推荐系统冷启动问题" class="headerlink" title="4.推荐系统冷启动问题"></a>4.推荐系统冷启动问题</h2><blockquote><h4 id="冷启动主要分为三类"><a href="#冷启动主要分为三类" class="headerlink" title="冷启动主要分为三类"></a>冷启动主要分为三类</h4><ul><li><h6 id="用户冷启动：主要是一个新用户，没有他的行为数据和历史数据，如何给他做推荐"><a href="#用户冷启动：主要是一个新用户，没有他的行为数据和历史数据，如何给他做推荐" class="headerlink" title="用户冷启动：主要是一个新用户，没有他的行为数据和历史数据，如何给他做推荐"></a>用户冷启动：主要是一个新用户，没有他的行为数据和历史数据，如何给他做推荐</h6></li><li><h6 id="物品冷启动：主要是解决如何将新品推荐给可能对它有兴趣的用户"><a href="#物品冷启动：主要是解决如何将新品推荐给可能对它有兴趣的用户" class="headerlink" title="物品冷启动：主要是解决如何将新品推荐给可能对它有兴趣的用户"></a>物品冷启动：主要是解决如何将新品推荐给可能对它有兴趣的用户</h6></li><li><h6 id="系统冷启动：解决如何在一个新开发的网站上-设计个性化推荐"><a href="#系统冷启动：解决如何在一个新开发的网站上-设计个性化推荐" class="headerlink" title="系统冷启动：解决如何在一个新开发的网站上,设计个性化推荐"></a>系统冷启动：解决如何在一个新开发的网站上,设计个性化推荐</h6></li></ul><h4 id="利用用户的注册信息：人口统计学-年龄，性别，职业，民族，学历，居住地-，用户兴趣的描述-有的网站注册时会让你打标签或用文字描述兴趣-，从其他网站导入的用户站外的行为-例如其他社交网站的行为数据"><a href="#利用用户的注册信息：人口统计学-年龄，性别，职业，民族，学历，居住地-，用户兴趣的描述-有的网站注册时会让你打标签或用文字描述兴趣-，从其他网站导入的用户站外的行为-例如其他社交网站的行为数据" class="headerlink" title="利用用户的注册信息：人口统计学(年龄，性别，职业，民族，学历，居住地)，用户兴趣的描述(有的网站注册时会让你打标签或用文字描述兴趣)，从其他网站导入的用户站外的行为(例如其他社交网站的行为数据)"></a>利用用户的注册信息：人口统计学(年龄，性别，职业，民族，学历，居住地)，用户兴趣的描述(有的网站注册时会让你打标签或用文字描述兴趣)，从其他网站导入的用户站外的行为(例如其他社交网站的行为数据)</h4><h6 id="获取用户信息，给用户分类，然后给用户推荐该类喜欢的物品"><a href="#获取用户信息，给用户分类，然后给用户推荐该类喜欢的物品" class="headerlink" title="获取用户信息，给用户分类，然后给用户推荐该类喜欢的物品"></a>获取用户信息，给用户分类，然后给用户推荐该类喜欢的物品</h6><h4 id="选择合适的物品启动用户的兴趣"><a href="#选择合适的物品启动用户的兴趣" class="headerlink" title="选择合适的物品启动用户的兴趣"></a>选择合适的物品启动用户的兴趣</h4><h6 id="当用户第一次访问时，让用户为一系列物品打分，然后根据反馈给出个性化推荐，给出的物品要比较热门，具有代表性和区分性，启动物品要有多样性"><a href="#当用户第一次访问时，让用户为一系列物品打分，然后根据反馈给出个性化推荐，给出的物品要比较热门，具有代表性和区分性，启动物品要有多样性" class="headerlink" title="当用户第一次访问时，让用户为一系列物品打分，然后根据反馈给出个性化推荐，给出的物品要比较热门，具有代表性和区分性，启动物品要有多样性"></a>当用户第一次访问时，让用户为一系列物品打分，然后根据反馈给出个性化推荐，给出的物品要比较热门，具有代表性和区分性，启动物品要有多样性</h6><h4 id="利用物品的内容信息"><a href="#利用物品的内容信息" class="headerlink" title="利用物品的内容信息"></a>利用物品的内容信息</h4><h6 id="物品的内容信息是多样的，不同类型的物品有不同的内容信息，例如电影，一般是标题，导演，演员，编剧，剧情，风格，国家，年代。如果是图书，一般包括标题，作者，出版社，正文，分类"><a href="#物品的内容信息是多样的，不同类型的物品有不同的内容信息，例如电影，一般是标题，导演，演员，编剧，剧情，风格，国家，年代。如果是图书，一般包括标题，作者，出版社，正文，分类" class="headerlink" title="物品的内容信息是多样的，不同类型的物品有不同的内容信息，例如电影，一般是标题，导演，演员，编剧，剧情，风格，国家，年代。如果是图书，一般包括标题，作者，出版社，正文，分类"></a>物品的内容信息是多样的，不同类型的物品有不同的内容信息，例如电影，一般是标题，导演，演员，编剧，剧情，风格，国家，年代。如果是图书，一般包括标题，作者，出版社，正文，分类</h6><table><thead><tr><th>图书</th><th>标题、作者、出版社、出版年代、丛书名、目录、正文</th></tr></thead><tbody><tr><td>论文</td><td>标题、作者、作者单位、关键字、分类、摘要、正文</td></tr><tr><td>电影</td><td>标题、导演、演员、编剧、类别、剧情简介、发行公司</td></tr><tr><td>新闻</td><td>标题、正文、来源、作者</td></tr><tr><td>微博</td><td>作者、内容、评论</td></tr></tbody></table><h6 id="物品的内容可以用向量空间模型表示，该模型会将物品表示成一个关键词向量。TF-IDF"><a href="#物品的内容可以用向量空间模型表示，该模型会将物品表示成一个关键词向量。TF-IDF" class="headerlink" title="物品的内容可以用向量空间模型表示，该模型会将物品表示成一个关键词向量。TF-IDF"></a>物品的内容可以用向量空间模型表示，该模型会将物品表示成一个关键词向量。TF-IDF</h6><h6 id="TF-IDF是一种统计方法，用于统计一字词对一个文件集或者一个语料库中的其中一份文件的的重要程度，字词的重要程度随着它在文件中出现的次数成正比，但同时随着在整个语料库中出现的频率成反比。"><a href="#TF-IDF是一种统计方法，用于统计一字词对一个文件集或者一个语料库中的其中一份文件的的重要程度，字词的重要程度随着它在文件中出现的次数成正比，但同时随着在整个语料库中出现的频率成反比。" class="headerlink" title="TF-IDF是一种统计方法，用于统计一字词对一个文件集或者一个语料库中的其中一份文件的的重要程度，字词的重要程度随着它在文件中出现的次数成正比，但同时随着在整个语料库中出现的频率成反比。"></a>TF-IDF是一种统计方法，用于统计一字词对一个文件集或者一个语料库中的其中一份文件的的重要程度，字词的重要程度随着它在文件中出现的次数成正比，但同时随着在整个语料库中出现的频率成反比。</h6><h6 id="词频-term-frequency-TF-指的是某一个给定的词语在该文件中出现的次数，这个数字通常会被归一化，避免偏向长文本，因为长文本的词频更高"><a href="#词频-term-frequency-TF-指的是某一个给定的词语在该文件中出现的次数，这个数字通常会被归一化，避免偏向长文本，因为长文本的词频更高" class="headerlink" title="词频 (term frequency, TF)指的是某一个给定的词语在该文件中出现的次数，这个数字通常会被归一化，避免偏向长文本，因为长文本的词频更高"></a>词频 (term frequency, TF)指的是某一个给定的词语在该文件中出现的次数，这个数字通常会被归一化，避免偏向长文本，因为长文本的词频更高</h6></blockquote><blockquote><h6 id="逆向文件频率-inverse-document-frequency-IDF-一个词语重要性的度量，一般可由总文本数目除以包含该词语的文本数然后取对数得到，这里有考虑到特殊的情况，例如有的生僻词没有在文档中出现所以分母会为0，IDF就没有意义了，所以需要做一些平滑，使语料库没有出现的词也有一个合适的值，后面的-1是避免热词出现在每个文档中，IDF值会为0，导致TF-IDF整个值为0，影响整个算法过程"><a href="#逆向文件频率-inverse-document-frequency-IDF-一个词语重要性的度量，一般可由总文本数目除以包含该词语的文本数然后取对数得到，这里有考虑到特殊的情况，例如有的生僻词没有在文档中出现所以分母会为0，IDF就没有意义了，所以需要做一些平滑，使语料库没有出现的词也有一个合适的值，后面的-1是避免热词出现在每个文档中，IDF值会为0，导致TF-IDF整个值为0，影响整个算法过程" class="headerlink" title="逆向文件频率 (inverse document frequency, IDF)一个词语重要性的度量，一般可由总文本数目除以包含该词语的文本数然后取对数得到，这里有考虑到特殊的情况，例如有的生僻词没有在文档中出现所以分母会为0，IDF就没有意义了，所以需要做一些平滑，使语料库没有出现的词也有一个合适的值，后面的+1是避免热词出现在每个文档中，IDF值会为0，导致TF-IDF整个值为0，影响整个算法过程"></a>逆向文件频率 (inverse document frequency, IDF)一个词语重要性的度量，一般可由总文本数目除以包含该词语的文本数然后取对数得到，这里有考虑到特殊的情况，例如有的生僻词没有在文档中出现所以分母会为0，IDF就没有意义了，所以需要做一些平滑，使语料库没有出现的词也有一个合适的值，后面的+1是避免热词出现在每个文档中，IDF值会为0，导致TF-IDF整个值为0，影响整个算法过程</h6><p><img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190619/ca0b284cb31bc02b3e2c63217c3b0dd7.png" alt="file"><br><img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190619/566aa7cb9e10076a01a6edd3a67ef6d7.png" alt="file"></p><h6 id="这里没有参考文章的基于内容推荐，参考了另外的文章。上面已经大概讲了TF-IDF原理和算法，这里举例如何计算两个新闻的相似度，我们如何计算两篇文章的相似度呢。我们可以提取两个新闻的关键词，对比两个新闻的关键词是不是相同。"><a href="#这里没有参考文章的基于内容推荐，参考了另外的文章。上面已经大概讲了TF-IDF原理和算法，这里举例如何计算两个新闻的相似度，我们如何计算两篇文章的相似度呢。我们可以提取两个新闻的关键词，对比两个新闻的关键词是不是相同。" class="headerlink" title="这里没有参考文章的基于内容推荐，参考了另外的文章。上面已经大概讲了TF-IDF原理和算法，这里举例如何计算两个新闻的相似度，我们如何计算两篇文章的相似度呢。我们可以提取两个新闻的关键词，对比两个新闻的关键词是不是相同。"></a>这里没有参考文章的基于内容推荐，参考了另外的文章。上面已经大概讲了TF-IDF原理和算法，这里举例如何计算两个新闻的相似度，我们如何计算两篇文章的相似度呢。我们可以提取两个新闻的关键词，对比两个新闻的关键词是不是相同。</h6><h6 id="这里提供了一个思路，首先，建立一个用户喜好表，用户每看一篇新闻，我们就通过TF-IDF算出这篇新闻的”word-value”，然后插入用户喜好表，已经在喜好表里的词直接累加这个值，这样我们算出要推荐的新闻的”word-value”-然后取两篇文章重复关键词的集合，将TF-IDF值累加，即为相似度"><a href="#这里提供了一个思路，首先，建立一个用户喜好表，用户每看一篇新闻，我们就通过TF-IDF算出这篇新闻的”word-value”，然后插入用户喜好表，已经在喜好表里的词直接累加这个值，这样我们算出要推荐的新闻的”word-value”-然后取两篇文章重复关键词的集合，将TF-IDF值累加，即为相似度" class="headerlink" title="这里提供了一个思路，首先，建立一个用户喜好表，用户每看一篇新闻，我们就通过TF-IDF算出这篇新闻的”word-value”，然后插入用户喜好表，已经在喜好表里的词直接累加这个值，这样我们算出要推荐的新闻的”word_value”,然后取两篇文章重复关键词的集合，将TF-IDF值累加，即为相似度"></a>这里提供了一个思路，首先，建立一个用户喜好表，用户每看一篇新闻，我们就通过TF-IDF算出这篇新闻的”word-value”，然后插入用户喜好表，已经在喜好表里的词直接累加这个值，这样我们算出要推荐的新闻的”word_value”,然后取两篇文章重复关键词的集合，将TF-IDF值累加，即为相似度</h6><h6 id="兴趣衰减：上面根据每篇新闻算出的”word-value”得到的用户喜好表可能在一段时间后，用户对某一类新闻没有兴趣里，导致该关键词一直在表里，这会导致我算相似度是会有影响，这里引入一个衰减机制0-lt-λ-lt-1系数，每隔一段时间，对每个关键词进行-λ衰减，当达到一个阈值之后直接将关键词删掉"><a href="#兴趣衰减：上面根据每篇新闻算出的”word-value”得到的用户喜好表可能在一段时间后，用户对某一类新闻没有兴趣里，导致该关键词一直在表里，这会导致我算相似度是会有影响，这里引入一个衰减机制0-lt-λ-lt-1系数，每隔一段时间，对每个关键词进行-λ衰减，当达到一个阈值之后直接将关键词删掉" class="headerlink" title="兴趣衰减：上面根据每篇新闻算出的”word-value”得到的用户喜好表可能在一段时间后，用户对某一类新闻没有兴趣里，导致该关键词一直在表里，这会导致我算相似度是会有影响，这里引入一个衰减机制0<λ<1系数，每隔一段时间，对每个关键词进行*λ衰减，当达到一个阈值之后直接将关键词删掉"></a>兴趣衰减：上面根据每篇新闻算出的”word-value”得到的用户喜好表可能在一段时间后，用户对某一类新闻没有兴趣里，导致该关键词一直在表里，这会导致我算相似度是会有影响，这里引入一个衰减机制0&lt;λ&lt;1系数，每隔一段时间，对每个关键词进行*λ衰减，当达到一个阈值之后直接将关键词删掉</h6><h6 id="https-blog-csdn-net-qq-32690999-article-details-77434381"><a href="#https-blog-csdn-net-qq-32690999-article-details-77434381" class="headerlink" title="https://blog.csdn.net/qq_32690999/article/details/77434381"></a><a href="https://blog.csdn.net/qq_32690999/article/details/77434381" target="_blank" rel="noopener">https://blog.csdn.net/qq_32690999/article/details/77434381</a></h6><h6 id="专家系统"><a href="#专家系统" class="headerlink" title="专家系统"></a>专家系统</h6></blockquote><h2 id="4-利用用户标签数据"><a href="#4-利用用户标签数据" class="headerlink" title="4.利用用户标签数据"></a>4.利用用户标签数据</h2><blockquote><h4 id="标签系统代表应用"><a href="#标签系统代表应用" class="headerlink" title="标签系统代表应用"></a>标签系统代表应用</h4><h4 id="Delicious"><a href="#Delicious" class="headerlink" title="Delicious"></a>Delicious</h4><h6 id="允许用户给互联网上的每个网页打标签，从而通过标签重新组织整个互联网"><a href="#允许用户给互联网上的每个网页打标签，从而通过标签重新组织整个互联网" class="headerlink" title="允许用户给互联网上的每个网页打标签，从而通过标签重新组织整个互联网"></a>允许用户给互联网上的每个网页打标签，从而通过标签重新组织整个互联网</h6><h4 id="CiteULike"><a href="#CiteULike" class="headerlink" title="CiteULike"></a>CiteULike</h4><h6 id="允许用户提交或收藏自己感兴趣的论文并给论文打标签"><a href="#允许用户提交或收藏自己感兴趣的论文并给论文打标签" class="headerlink" title="允许用户提交或收藏自己感兴趣的论文并给论文打标签"></a>允许用户提交或收藏自己感兴趣的论文并给论文打标签</h6><h4 id="Last-fm"><a href="#Last-fm" class="headerlink" title="Last.fm"></a>Last.fm</h4><h6 id="音乐不像文本那样容易分析内容信息，为了在不进行复杂音频分析的情况下获得音乐的内容信息，引入了UGC标签系统，让用户用标签标记音乐和歌手。"><a href="#音乐不像文本那样容易分析内容信息，为了在不进行复杂音频分析的情况下获得音乐的内容信息，引入了UGC标签系统，让用户用标签标记音乐和歌手。" class="headerlink" title="音乐不像文本那样容易分析内容信息，为了在不进行复杂音频分析的情况下获得音乐的内容信息，引入了UGC标签系统，让用户用标签标记音乐和歌手。"></a>音乐不像文本那样容易分析内容信息，为了在不进行复杂音频分析的情况下获得音乐的内容信息，引入了UGC标签系统，让用户用标签标记音乐和歌手。</h6><h4 id="豆瓣"><a href="#豆瓣" class="headerlink" title="豆瓣"></a>豆瓣</h4><h6 id="允许用户对图书和电影打标签，借此获得图书和电影的内容信息和语义"><a href="#允许用户对图书和电影打标签，借此获得图书和电影的内容信息和语义" class="headerlink" title="允许用户对图书和电影打标签，借此获得图书和电影的内容信息和语义"></a>允许用户对图书和电影打标签，借此获得图书和电影的内容信息和语义</h6><h4 id="Hulu"><a href="#Hulu" class="headerlink" title="Hulu"></a>Hulu</h4><h6 id="视频作为一种复杂的多媒体，获取它的内容信息是最困难的，因此也引入了用户标签系统来让用户对电视剧和电影进行标记"><a href="#视频作为一种复杂的多媒体，获取它的内容信息是最困难的，因此也引入了用户标签系统来让用户对电视剧和电影进行标记" class="headerlink" title="视频作为一种复杂的多媒体，获取它的内容信息是最困难的，因此也引入了用户标签系统来让用户对电视剧和电影进行标记"></a>视频作为一种复杂的多媒体，获取它的内容信息是最困难的，因此也引入了用户标签系统来让用户对电视剧和电影进行标记</h6><h4 id="标签系统中的标签分类"><a href="#标签系统中的标签分类" class="headerlink" title="标签系统中的标签分类"></a>标签系统中的标签分类</h4><h6 id="表明物体是什么：例如一只鸟，标签就是鸟，豆瓣首页，标签就是豆瓣"><a href="#表明物体是什么：例如一只鸟，标签就是鸟，豆瓣首页，标签就是豆瓣" class="headerlink" title="表明物体是什么：例如一只鸟，标签就是鸟，豆瓣首页，标签就是豆瓣"></a>表明物体是什么：例如一只鸟，标签就是鸟，豆瓣首页，标签就是豆瓣</h6><h6 id="表明物品的种类：例如为一篇新闻，标签可以是军事，科技"><a href="#表明物品的种类：例如为一篇新闻，标签可以是军事，科技" class="headerlink" title="表明物品的种类：例如为一篇新闻，标签可以是军事，科技"></a>表明物品的种类：例如为一篇新闻，标签可以是军事，科技</h6><h6 id="表明谁拥有物品：博客的作者"><a href="#表明谁拥有物品：博客的作者" class="headerlink" title="表明谁拥有物品：博客的作者"></a>表明谁拥有物品：博客的作者</h6><h6 id="表明用户的观点：funny，boring"><a href="#表明用户的观点：funny，boring" class="headerlink" title="表明用户的观点：funny，boring"></a>表明用户的观点：funny，boring</h6><h6 id="根据标签推荐：这里有了每个用户的标签和每个标签的数量之后，可以用之前的用户相似度，物品相似度，或者TF—IDF做推荐都可以"><a href="#根据标签推荐：这里有了每个用户的标签和每个标签的数量之后，可以用之前的用户相似度，物品相似度，或者TF—IDF做推荐都可以" class="headerlink" title="根据标签推荐：这里有了每个用户的标签和每个标签的数量之后，可以用之前的用户相似度，物品相似度，或者TF—IDF做推荐都可以"></a>根据标签推荐：这里有了每个用户的标签和每个标签的数量之后，可以用之前的用户相似度，物品相似度，或者TF—IDF做推荐都可以</h6></blockquote><h2 id="5-利用上下文信息"><a href="#5-利用上下文信息" class="headerlink" title="5.利用上下文信息"></a>5.利用上下文信息</h2><blockquote><h4 id="上下文，例如时间，天气，地点，等能够影响到用户决策的额外信息"><a href="#上下文，例如时间，天气，地点，等能够影响到用户决策的额外信息" class="headerlink" title="上下文，例如时间，天气，地点，等能够影响到用户决策的额外信息"></a>上下文，例如时间，天气，地点，等能够影响到用户决策的额外信息</h4><h4 id="时间上下文"><a href="#时间上下文" class="headerlink" title="时间上下文"></a>时间上下文</h4><h6 id="用户兴趣是随着时间变化的：关注用户的最近行为最能体现他的兴趣，当然考虑用户最近的兴趣只能针对渐变的用户兴趣，针对用户突变的行为很难起到作用"><a href="#用户兴趣是随着时间变化的：关注用户的最近行为最能体现他的兴趣，当然考虑用户最近的兴趣只能针对渐变的用户兴趣，针对用户突变的行为很难起到作用" class="headerlink" title="用户兴趣是随着时间变化的：关注用户的最近行为最能体现他的兴趣，当然考虑用户最近的兴趣只能针对渐变的用户兴趣，针对用户突变的行为很难起到作用"></a>用户兴趣是随着时间变化的：关注用户的最近行为最能体现他的兴趣，当然考虑用户最近的兴趣只能针对渐变的用户兴趣，针对用户突变的行为很难起到作用</h6><h6 id="物品是有生命周期的：比如一部电影刚上映可能会有很多关注，但是过一段时间可能就被淡忘了，不过电影有可能因为一些事件重新热门起来。又例如你推荐一个几年前的新闻给用户，明显不太合适，除非用户在寻找几年前的新闻。一般来说我们推荐某个物品是要考虑物品当时是否过时。不同的系统物品的生命周期不同，电影的生命周期大于新闻的生命周期"><a href="#物品是有生命周期的：比如一部电影刚上映可能会有很多关注，但是过一段时间可能就被淡忘了，不过电影有可能因为一些事件重新热门起来。又例如你推荐一个几年前的新闻给用户，明显不太合适，除非用户在寻找几年前的新闻。一般来说我们推荐某个物品是要考虑物品当时是否过时。不同的系统物品的生命周期不同，电影的生命周期大于新闻的生命周期" class="headerlink" title="物品是有生命周期的：比如一部电影刚上映可能会有很多关注，但是过一段时间可能就被淡忘了，不过电影有可能因为一些事件重新热门起来。又例如你推荐一个几年前的新闻给用户，明显不太合适，除非用户在寻找几年前的新闻。一般来说我们推荐某个物品是要考虑物品当时是否过时。不同的系统物品的生命周期不同，电影的生命周期大于新闻的生命周期"></a>物品是有生命周期的：比如一部电影刚上映可能会有很多关注，但是过一段时间可能就被淡忘了，不过电影有可能因为一些事件重新热门起来。又例如你推荐一个几年前的新闻给用户，明显不太合适，除非用户在寻找几年前的新闻。一般来说我们推荐某个物品是要考虑物品当时是否过时。不同的系统物品的生命周期不同，电影的生命周期大于新闻的生命周期</h6><h6 id="季节效应：夏天穿T恤，冬天穿棉袄，夏天吃冷饮，冬天喝热饮，还有一些固定的节假日，例如国外的圣诞节，情人节，国内的七夕，中秋，端午"><a href="#季节效应：夏天穿T恤，冬天穿棉袄，夏天吃冷饮，冬天喝热饮，还有一些固定的节假日，例如国外的圣诞节，情人节，国内的七夕，中秋，端午" class="headerlink" title="季节效应：夏天穿T恤，冬天穿棉袄，夏天吃冷饮，冬天喝热饮，还有一些固定的节假日，例如国外的圣诞节，情人节，国内的七夕，中秋，端午"></a>季节效应：夏天穿T恤，冬天穿棉袄，夏天吃冷饮，冬天喝热饮，还有一些固定的节假日，例如国外的圣诞节，情人节，国内的七夕，中秋，端午</h6><h6 id="不同的系统物品生命周期和流行度"><a href="#不同的系统物品生命周期和流行度" class="headerlink" title="不同的系统物品生命周期和流行度"></a>不同的系统物品生命周期和流行度</h6><p><img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190711/1e11e8ba9630534fb6d84f2a746d3805.png" alt="file"></p><h6 id="物品流行度度量和平均相似度：取系统中相隔T天的两天，计算这两天的物品流行度，用余弦公式算出这两天的相似度，如果相似度大，说明系统的时效性不强，物品平均在线时间较长，如果相似度小，说明物品发生了较大的变化，系统的时效性较强，物品平均在线时间很短"><a href="#物品流行度度量和平均相似度：取系统中相隔T天的两天，计算这两天的物品流行度，用余弦公式算出这两天的相似度，如果相似度大，说明系统的时效性不强，物品平均在线时间较长，如果相似度小，说明物品发生了较大的变化，系统的时效性较强，物品平均在线时间很短" class="headerlink" title="物品流行度度量和平均相似度：取系统中相隔T天的两天，计算这两天的物品流行度，用余弦公式算出这两天的相似度，如果相似度大，说明系统的时效性不强，物品平均在线时间较长，如果相似度小，说明物品发生了较大的变化，系统的时效性较强，物品平均在线时间很短"></a>物品流行度度量和平均相似度：取系统中相隔T天的两天，计算这两天的物品流行度，用余弦公式算出这两天的相似度，如果相似度大，说明系统的时效性不强，物品平均在线时间较长，如果相似度小，说明物品发生了较大的变化，系统的时效性较强，物品平均在线时间很短</h6><p><img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190711/5f8efc0538fabfbbd7f3cf67bcc85657.png" alt="file"><br><img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190711/725c6881112fbfeb8494187727ac665b.png" alt="file"><br><img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190711/aa15c1107284af788e3e5875ed967589.png" alt="file"></p></blockquote><blockquote><h4 id="地点上下文"><a href="#地点上下文" class="headerlink" title="地点上下文"></a>地点上下文</h4></blockquote><h2 id="6-利用社交网络"><a href="#6-利用社交网络" class="headerlink" title="6.利用社交网络"></a>6.利用社交网络</h2><blockquote><h4 id="基于社交网络的推荐"><a href="#基于社交网络的推荐" class="headerlink" title="基于社交网络的推荐"></a>基于社交网络的推荐</h4><h6 id="好友推荐可以增加推荐信任度"><a href="#好友推荐可以增加推荐信任度" class="headerlink" title="好友推荐可以增加推荐信任度"></a>好友推荐可以增加推荐信任度</h6><h6 id="社交网络可以解决冷启动"><a href="#社交网络可以解决冷启动" class="headerlink" title="社交网络可以解决冷启动"></a>社交网络可以解决冷启动</h6><h6 id="缺点：不一定能提高精度，因为社交网络是基于好友关系，并不是基于用户的兴趣。"><a href="#缺点：不一定能提高精度，因为社交网络是基于好友关系，并不是基于用户的兴趣。" class="headerlink" title="缺点：不一定能提高精度，因为社交网络是基于好友关系，并不是基于用户的兴趣。"></a>缺点：不一定能提高精度，因为社交网络是基于好友关系，并不是基于用户的兴趣。</h6><h4 id="基于邻域的社会化推荐算法"><a href="#基于邻域的社会化推荐算法" class="headerlink" title="基于邻域的社会化推荐算法"></a>基于邻域的社会化推荐算法</h4><h6 id="一般来说，用户更加相信自己熟悉的好友的推荐，因此我们需要考虑用户之间的熟悉度。熟悉度可以用用户之间的共同好友比例来度量。也就是说如果用户u和用户v很熟悉，那么一般来说他们应该有很多共同的好友。"><a href="#一般来说，用户更加相信自己熟悉的好友的推荐，因此我们需要考虑用户之间的熟悉度。熟悉度可以用用户之间的共同好友比例来度量。也就是说如果用户u和用户v很熟悉，那么一般来说他们应该有很多共同的好友。" class="headerlink" title="一般来说，用户更加相信自己熟悉的好友的推荐，因此我们需要考虑用户之间的熟悉度。熟悉度可以用用户之间的共同好友比例来度量。也就是说如果用户u和用户v很熟悉，那么一般来说他们应该有很多共同的好友。"></a>一般来说，用户更加相信自己熟悉的好友的推荐，因此我们需要考虑用户之间的熟悉度。熟悉度可以用用户之间的共同好友比例来度量。也就是说如果用户u和用户v很熟悉，那么一般来说他们应该有很多共同的好友。</h6><h6 id="除了熟悉程度，还需要考虑用户之间的兴趣相似度。我们都和父母很熟悉-但很多时候我们和父母的兴趣却不相似，因此也不会喜欢他们喜欢的物品。"><a href="#除了熟悉程度，还需要考虑用户之间的兴趣相似度。我们都和父母很熟悉-但很多时候我们和父母的兴趣却不相似，因此也不会喜欢他们喜欢的物品。" class="headerlink" title="除了熟悉程度，还需要考虑用户之间的兴趣相似度。我们都和父母很熟悉,但很多时候我们和父母的兴趣却不相似，因此也不会喜欢他们喜欢的物品。"></a>除了熟悉程度，还需要考虑用户之间的兴趣相似度。我们都和父母很熟悉,但很多时候我们和父母的兴趣却不相似，因此也不会喜欢他们喜欢的物品。</h6><p><img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190711/f046060e2898a19d0f3bc3957600abdb.png" alt="file"></p></blockquote><p>信息熵 H 单位比特 一件事物的不确定性，<br>信息的度量，减少不确定性 事物的微观态 = 1/p * log2 ^ 1/p </p><p><img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190711/f183f75188c25d0dac880553d4c2c43e.png" alt="file"></p><p><img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190711/f878224887a93d2298b2d4dd70b53018.png" alt="file"></p><p>混淆矩阵：<br>    准确率<br>    精确率<br>    召回率</p><p>准确度(Accuracy) = (TP+TN) / (TP+TN+FN+TN)<br>精确度(precision, 或者PPV, positive predictive value) = TP / (TP + FP)<br>召回(recall, 或者敏感度，sensitivity，真阳性率，TPR，True Positive Rate) = TP / (TP + FN)<br>F1 = 2 * (precision) * recall/(precision+recall)</p><table><thead><tr><th></th><th>Yes</th><th>No</th><th>预测值</th></tr></thead><tbody><tr><td>Yes</td><td>TP = 45</td><td>FN = 5</td><td>P = 50</td></tr><tr><td>No</td><td>FP =  0</td><td>TN = 50</td><td>N = 50</td></tr><tr><td>真实值</td><td>P’ = 45</td><td>N’ = 55</td><td>P+N = 100</td></tr></tbody></table><blockquote><p>正确率：(TP+TN )/(P+N)  = 95 /100 = 0.95</p></blockquote><blockquote><p>精  度(precision): TP/(TP+FP) = 45/45 = 1</p></blockquote><blockquote><p>召回率(recall)：TP/P = 45/50 = 0.9</p></blockquote><blockquote><p>F1 = 2 * (precision) * recall/(precision+recall)<br>       = 2 * 1 * 0.9/(1+0.9)<br>       = 0.947</p></blockquote><p><img src="https://static-cdn.verystar.net/s/pay/verydoc/pic/20190711/41e857d803b197c5d9e763a4f8a51145.png" alt="file"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 推荐系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pandas 讲解</title>
      <link href="/2019/11/05/pandas-jiang-jie/"/>
      <url>/2019/11/05/pandas-jiang-jie/</url>
      
        <content type="html"><![CDATA[<p><img src="https://blog.mazhangjing.com/media/mdf.png" alt=""></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd <span class="token comment" spellcheck="true"># 取行</span>df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true"># 取列</span>df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Animal'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'Animal'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true"># 取指定行指定列</span>df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'Animal'</span><span class="token punctuation">,</span><span class="token string">'Owners'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'Animal'</span><span class="token punctuation">:</span><span class="token string">'Owners'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd <span class="token comment" spellcheck="true"># 常用函数</span>df<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">.</span>describe<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 常用属性</span>df<span class="token punctuation">.</span>shapedf<span class="token punctuation">.</span>dtypesdf<span class="token punctuation">.</span>info<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd <span class="token comment" spellcheck="true"># 常见字符串操作</span>df<span class="token punctuation">.</span>Animal<span class="token punctuation">.</span>str<span class="token punctuation">.</span>contains<span class="token punctuation">(</span><span class="token string">'Dog'</span><span class="token punctuation">)</span>df<span class="token punctuation">.</span>Animal<span class="token punctuation">.</span>str<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span>df<span class="token punctuation">.</span>Animal<span class="token punctuation">.</span>str<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'Dog'</span><span class="token punctuation">,</span><span class="token string">'dog'</span><span class="token punctuation">)</span>df<span class="token punctuation">.</span>Animal<span class="token punctuation">.</span>str<span class="token punctuation">.</span>upper<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd <span class="token comment" spellcheck="true"># 常见连表操作</span>df<span class="token punctuation">.</span>merge<span class="token punctuation">(</span>df1<span class="token punctuation">,</span>df2<span class="token punctuation">,</span>on<span class="token operator">=</span><span class="token string">'xx'</span><span class="token punctuation">,</span>how<span class="token operator">=</span><span class="token string">'inner'</span><span class="token punctuation">)</span>df<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>df1<span class="token punctuation">,</span>df2<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Merge 函数在作为主键的指定公共列上合并多个 dataframe</code></pre><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201807/5b4dabc290241.png?imageMogr2/format/jpg/quality/90" alt=""></p><pre><code>Concat 函数可以在下方或旁边合并一个或多个 dataframe</code></pre><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201807/5b4daba39bba9.png?imageMogr2/format/jpg/quality/90" alt=""></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd <span class="token comment" spellcheck="true"># 好用的函数之map（有类似匹配映射时可以使用）</span>df<span class="token punctuation">.</span>Animal<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span><span class="token string">'贵'</span> <span class="token keyword">if</span> x<span class="token operator">></span><span class="token number">10</span> <span class="token keyword">else</span> <span class="token string">'便宜'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 好用的函数之apply（对dataframe的每一列应用函数）</span>df<span class="token punctuation">.</span>Animal<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span><span class="token string">'贵'</span> <span class="token keyword">if</span> x<span class="token operator">></span><span class="token number">10</span> <span class="token keyword">else</span> <span class="token string">'便宜'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 好用的函数之applymap（对dataframe的每一列应用函数）</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>pandas和sql的比较</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd <span class="token comment" spellcheck="true"># pandas 之 select</span>df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Animal'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token string">'Animal'</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true"># 好用的函数之apply（对dataframe的每一列应用函数）</span>df<span class="token punctuation">.</span>Animal<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span><span class="token string">'贵'</span> <span class="token keyword">if</span> x<span class="token operator">></span><span class="token number">10</span> <span class="token keyword">else</span> <span class="token string">'便宜'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 好用的函数之applymap（对dataframe的每一列应用函数）</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
